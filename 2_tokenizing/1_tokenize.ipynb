{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tokenizing_functions import extract_events, get_file_and_dirnames\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PATH_TRANSPOSED = \"../0_data/4_preprocessed_sets\"\n",
    "PATH_VOCAB = \"../0_data/5_vocabs\"\n",
    "PATH_WORD_DATA = \"../0_data/6_word_data\"\n",
    "\n",
    "for path in [PATH_VOCAB, PATH_WORD_DATA]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vocabulary configs for all six models\n",
    "vocab_configs = {\n",
    "    \"a1\" : {\n",
    "        \"pitch_start\": 0,\n",
    "        \"pitch_end\": 127,\n",
    "        \"duration_steps\": 64,\n",
    "        \"triole_tokens\": False,\n",
    "        \"folder_name\": \"a)_4_4_metric_120_bpm\"\n",
    "    },\n",
    "    \"a2\" : {\n",
    "        \"pitch_start\": 0,\n",
    "        \"pitch_end\": 127,\n",
    "        \"duration_steps\": 64,\n",
    "        \"triole_tokens\": True,\n",
    "        \"folder_name\": \"a)_4_4_metric_120_bpm\"\n",
    "    },\n",
    "    \"a3\" : {\n",
    "        \"pitch_start\": 0,\n",
    "        \"pitch_end\": 127,\n",
    "        \"duration_steps\": 32,\n",
    "        \"triole_tokens\": False,\n",
    "        \"folder_name\": \"a)_4_4_metric_120_bpm\"\n",
    "    },\n",
    "    \"b\" : {\n",
    "        \"pitch_start\": 0,\n",
    "        \"pitch_end\": 127,\n",
    "        \"duration_steps\": 64,\n",
    "        \"triole_tokens\": False,\n",
    "        \"folder_name\": \"b)_transposed_key\"\n",
    "    },\n",
    "    \"c\" : {\n",
    "        \"pitch_start\": 60,\n",
    "        \"pitch_end\": 95,\n",
    "        \"duration_steps\": 64,\n",
    "        \"triole_tokens\": False,\n",
    "        \"folder_name\": \"c)_transposed_octave\"\n",
    "    },\n",
    "    \"d\" : {\n",
    "        \"pitch_start\": 60,\n",
    "        \"pitch_end\": 95,\n",
    "        \"duration_steps\": 32,\n",
    "        \"triole_tokens\": True,\n",
    "        \"folder_name\": \"d)_transposed_key_and_octave\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vocabulary for each model\n",
    "\n",
    "POSITION_STEPS = 16\n",
    "TICKS_PER_BEAT = 1024\n",
    "TRIOLE_POS_1 = (TICKS_PER_BEAT/12).__round__()\n",
    "TRIOLE_POS_2 = (TICKS_PER_BEAT/6).__round__()\n",
    "TICKS_PER_MIN_DURATION = TICKS_PER_BEAT*4/32\n",
    "\n",
    "for key in vocab_configs:\n",
    "\n",
    "    duration_steps = vocab_configs[key][\"duration_steps\"]\n",
    "    pitch_start = vocab_configs[key][\"pitch_start\"]\n",
    "    pitch_end = vocab_configs[key][\"pitch_end\"]\n",
    "    pitch_range = pitch_end - pitch_start + 1\n",
    "    triole_tokens = vocab_configs[key][\"triole_tokens\"]\n",
    "\n",
    "    # 1 Bar token\n",
    "    token2word = {0: \"Bar_None\"}\n",
    "    # 36 or 128 Note-On tokens\n",
    "    for i in range(1, pitch_range+1):\n",
    "        token2word[i] = f\"Note-On_{i+pitch_start-1}\"\n",
    "    # 32 or 64 Note-Duration tokens\n",
    "    for i in range(pitch_range+1, pitch_range+duration_steps+1):\n",
    "        token2word[i] = f\"Note-Duration_{i-pitch_range}\"\n",
    "    # 1 duration triole token if triole_tokens is True\n",
    "    if triole_tokens:\n",
    "        token2word[pitch_range+duration_steps+1] = \"Note-Duration_triole\"\n",
    "        start_position_tokens = pitch_range+duration_steps+2\n",
    "    else:\n",
    "        start_position_tokens = pitch_range+duration_steps+1\n",
    "    # 16 Position tokens\n",
    "    for i in range(start_position_tokens, start_position_tokens+POSITION_STEPS):\n",
    "        token2word[i] = f\"Position_{i-start_position_tokens+1}/{POSITION_STEPS}\"\n",
    "    # 2 Position triole tokens if triole_tokens is True\n",
    "    if triole_tokens:\n",
    "        token2word[start_position_tokens+POSITION_STEPS] = \"Position-Triole_1\"\n",
    "        token2word[start_position_tokens+POSITION_STEPS+1] = \"Position-Triole_2\"\n",
    "\n",
    "    word2token = {v: k for k, v in token2word.items()}\n",
    "    vocab_configs[key][\"word2token\"] = word2token\n",
    "    \n",
    "    with open(f\"{PATH_VOCAB}/vocab_{key}.json\", \"w\") as fp:\n",
    "        json.dump(word2token, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 803/803 [00:17<00:00, 44.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 :  803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 803/803 [00:21<00:00, 37.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2 :  803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 803/803 [00:17<00:00, 45.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3 :  803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 803/803 [00:17<00:00, 45.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b :  803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 803/803 [00:17<00:00, 45.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c :  803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 803/803 [00:20<00:00, 38.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d :  803\n"
     ]
    }
   ],
   "source": [
    "# get files, tokenize them for all six models and save tokenized data as json files\n",
    "\n",
    "folder_name = vocab_configs[\"d\"][\"folder_name\"]\n",
    "files,_ = get_file_and_dirnames(f\"{PATH_TRANSPOSED}/{folder_name}/17_POP909-Dataset-master\")\n",
    "files.sort()\n",
    "\n",
    "for key in vocab_configs:\n",
    "\n",
    "    folder_name = vocab_configs[key][\"folder_name\"]\n",
    "    dir = f\"{PATH_TRANSPOSED}/{folder_name}/17_POP909-Dataset-master\"\n",
    "\n",
    "    # process midi files into word sequences\n",
    "    word_data = {}\n",
    "    token_data = {}\n",
    "    for file in tqdm(files):\n",
    "        path = f\"{dir}/{file}\"\n",
    "        events =extract_events(path, vocab_configs[key][\"duration_steps\"], vocab_configs[key][\"triole_tokens\"])\n",
    "        words = [f\"{e['name']}_{e['value']}\" for e in events]\n",
    "        word_data[file] = words\n",
    "        tokens = [vocab_configs[key][\"word2token\"][word] for word in words]\n",
    "        token_data[file] = tokens\n",
    "    print(key, \": \", len(word_data))\n",
    "\n",
    "    with open(f\"{PATH_WORD_DATA}/{key}_data.json\", \"w\") as fp:\n",
    "        json.dump(word_data, fp)\n",
    "    with open(f\"{PATH_WORD_DATA}/{key}_token_data.json\", \"w\") as fp:\n",
    "        json.dump(token_data, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "b45485cfab4f9d3f2b74db78e445236bebb198055b9cbaed4a83d587e72b6464"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
