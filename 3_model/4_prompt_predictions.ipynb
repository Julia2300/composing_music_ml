{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f97d2f-6ac1-4348-8876-690002b854db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_functions import predict, write_midi, get_token_flags\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Config, GPT2Tokenizer, GPT2LMHeadModel, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    "\n",
    "PATH_VOCAB = \"../0_data/5_vocabs\"\n",
    "PATH_DATA = \"../0_data/6_word_data\"\n",
    "PATH_MODELS = \"../0_data/7_models\"\n",
    "PATH_MODELS_CONFIG = \"../0_data/7_models/config\"\n",
    "PATH_PRED = \"../0_data/8_predictions\"\n",
    "PATH_TOKENS = \"../0_data/8_predictions/tokens\"\n",
    "PATH_MIDI = \"../0_data/8_predictions/midi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbfd68e1-0b3f-480c-91df-5934fa5e91b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vocabulary configs\n",
    "vocab_configs = {\n",
    "    \"a1\" : {\n",
    "        \"pitch_range\": 128,\n",
    "        \"duration_steps\": 64,\n",
    "        \"triole_tokens\": False,\n",
    "    },\n",
    "    \"a2\" : {\n",
    "        \"pitch_range\": 128,\n",
    "        \"duration_steps\": 64,\n",
    "        \"triole_tokens\": True,\n",
    "    },\n",
    "    \"a3\" : {\n",
    "        \"pitch_range\": 128,\n",
    "        \"duration_steps\": 32,\n",
    "        \"triole_tokens\": False,\n",
    "    },\n",
    "    \"b\" : {\n",
    "        \"pitch_range\": 128,\n",
    "        \"duration_steps\": 64,\n",
    "        \"triole_tokens\": False,\n",
    "    },\n",
    "    \"c\" : {\n",
    "        \"pitch_range\": 36,\n",
    "        \"duration_steps\": 64,\n",
    "        \"triole_tokens\": False,\n",
    "    },\n",
    "    \"d\" : {\n",
    "        \"pitch_range\": 36,\n",
    "        \"duration_steps\": 32,\n",
    "        \"triole_tokens\": True,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1af216a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:90 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:90 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midi saved in ../0_data/8_predictions/midi/d_prompts/040_generated_midi_0.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/d_prompts/040_generated_midi_1.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/d_prompts/040_generated_midi_2.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/d_prompts/040_generated_midi_3.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/d_prompts/040_generated_midi_4.midi\n",
      "Number of incorrect notes: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:90 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midi saved in ../0_data/8_predictions/midi/d_prompts/095_generated_midi_0.midi\n",
      "Number of incorrect notes: 1\n",
      "midi saved in ../0_data/8_predictions/midi/d_prompts/095_generated_midi_1.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/d_prompts/095_generated_midi_2.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/d_prompts/095_generated_midi_3.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/d_prompts/095_generated_midi_4.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/d_prompts/600_generated_midi_0.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/d_prompts/600_generated_midi_1.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/d_prompts/600_generated_midi_2.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/d_prompts/600_generated_midi_3.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/d_prompts/600_generated_midi_4.midi\n",
      "Number of incorrect notes: 0\n"
     ]
    }
   ],
   "source": [
    "# make prompt predctions and calculate correct note rate\n",
    "\n",
    "TICKS_PER_BEAT = 1024\n",
    "TICKS_PER_MIN_DURATION = TICKS_PER_BEAT*4/32\n",
    "\n",
    "model_name = \"d\"\n",
    "if not os.path.exists(f\"{PATH_MIDI}/{model_name}_prompts\"):\n",
    "        os.makedirs(f\"{PATH_MIDI}/{model_name}_prompts\")\n",
    "\n",
    "# get token flags and duration bins\n",
    "token_flags = get_token_flags(vocab_configs[model_name])\n",
    "duration_steps = vocab_configs[model_name][\"duration_steps\"]\n",
    "duration_bins = np.arange(TICKS_PER_MIN_DURATION, (TICKS_PER_MIN_DURATION*duration_steps)+1, TICKS_PER_MIN_DURATION, dtype=int)\n",
    "\n",
    "# create tokenizer\n",
    "tokenizer = GPT2Tokenizer(\n",
    "        vocab_file=f\"{PATH_VOCAB}/vocab_{model_name}.json\", \n",
    "        merges_file=f\"{PATH_VOCAB}/merges.txt\")\n",
    "tokenizer.add_special_tokens({'pad_token': 'PAD', 'bos_token': 'BOS', 'eos_token': 'EOS',})\n",
    "\n",
    "# get vocabulary\n",
    "with open(f\"{PATH_VOCAB}/vocab_{model_name}.json\", \"r\") as fp:\n",
    "        vocab = json.load(fp)\n",
    "token2word = {token: word for word, token in vocab.items()}\n",
    "\n",
    "# load model and prompt data\n",
    "model = GPT2LMHeadModel.from_pretrained(f\"{PATH_MODELS_CONFIG}/{model_name}/end_version\")\n",
    "with open(f\"{PATH_DATA}/prompt_data.json\", \"r\") as fp:\n",
    "        prompt_data = json.load(fp)\n",
    "\n",
    "# make predictions save\n",
    "data_generated = {}\n",
    "for prompt in prompt_data.keys():\n",
    "    output = predict(model, tokenizer, prompt=\" \".join(prompt_data[prompt]), samples=5, max_length=1024)\n",
    "    data_generated[prompt] = output\n",
    "    for i, pred in enumerate(output):\n",
    "        write_midi(output[i], token2word, duration_bins, f\"{PATH_MIDI}/{model_name}_prompts/{prompt[:3]}_generated_midi_{i}.midi\")\n",
    "        \n",
    "with open(f\"{PATH_TOKENS}/{model_name}_prompts.json\", \"w\") as fp:\n",
    "        json.dump(data_generated, fp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d416e543-751c-4d86-98cc-4697915c5669",
   "metadata": {},
   "source": [
    "run \"tar chvfz predictions_midi.tar.gz *\" in terminal midi folder to create and download zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MusicAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
