{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22ff8f9-cea1-42a2-8792-31b451e99e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import GPT2Config, GPT2Tokenizer, GPT2LMHeadModel, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f9159c4-96f5-4ec0-b354-ca07f7c23b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a0de7b-c342-4326-b1dd-b55e0c390cfc",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21991d5a-0ae8-4538-a265-ae220545b340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 803\n",
      "Example song sentence: Bar_None Position_3/16 Note-On_76 Note-Duration_2 Position_4/16 Note-On_74 Note-Duration_2 Position_\n"
     ]
    }
   ],
   "source": [
    "with open('data_words.json', 'r') as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "song_list = []\n",
    "for song in data:\n",
    "    song_list.append(data[song])\n",
    "\n",
    "print(\"Data length:\", len(song_list))\n",
    "\n",
    "song_sentences = [\" \".join(song) for song in song_list]\n",
    "print(\"Example song sentence:\", song_sentences[0][:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6327f311-3851-4e98-a3de-0571bb8d7bad",
   "metadata": {},
   "source": [
    "# Tokeinzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0b984b6-7c64-4f76-bfa8-48e2f715494f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  120\n",
      "PAD token:  120\n",
      "BOS token:  121\n",
      "EOS token:  122\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer(\n",
    "    vocab_file=\"vocab.json\", \n",
    "    merges_file=\"merges.txt\")\n",
    "\n",
    "tokenizer.add_special_tokens({'pad_token': 'PAD', 'bos_token': 'BOS', 'eos_token': 'EOS',})\n",
    "\n",
    "print(\"vocab size: \", tokenizer.vocab_size)\n",
    "print(\"PAD token: \", tokenizer.pad_token_id)\n",
    "print(\"BOS token: \", tokenizer.bos_token_id)\n",
    "print(\"EOS token: \", tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099462dd-d5cb-4224-90ef-5fdfe19c4b79",
   "metadata": {},
   "source": [
    "# Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87c75f54-132a-47d8-91ed-1d5c94d5a29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data length: 803\n",
      "90% at:      722\n"
     ]
    }
   ],
   "source": [
    "split_train_test = int(0.9*len(song_sentences))\n",
    "print(\"data length:\", len(song_sentences))\n",
    "print(\"90% at:     \", split_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5af33640-24c0-4470-87dd-377f93903bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = song_sentences[:split_train_test]\n",
    "eval_data = song_sentences[split_train_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c47d3a50-0167-41b9-a77d-c8c496f0a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetNew(Dataset):\n",
    "    def __init__(self, tokenizer, data, max_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            self.data[index].split(\" \"),\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "        labels = input_ids.clone()\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100  # Set padding tokens to -100 for language modeling\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "560c0bf4-dd12-47aa-9c15-316c55f66e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of your custom Dataset\n",
    "train_dataset = CustomDatasetNew(tokenizer=tokenizer, data=train_data, max_length=32)\n",
    "eval_dataset = CustomDatasetNew(tokenizer=tokenizer, data=eval_data, max_length=32)\n",
    "\n",
    "# Define your data collator\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9b20777-9d4a-46ce-b247-dbe52752d798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  0, 107, 118,   5,  38, 109,   8,  38, 111, 118,  10,  38, 113,  13,\n",
       "           44, 101, 115, 118,  12,  52, 101,   0, 103, 118,  10,  38, 105,   8,\n",
       "           38, 107, 118,  10]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'labels': tensor([[  0, 107, 118,   5,  38, 109,   8,  38, 111, 118,  10,  38, 113,  13,\n",
       "           44, 101, 115, 118,  12,  52, 101,   0, 103, 118,  10,  38, 105,   8,\n",
       "           38, 107, 118,  10]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de3950d-0cb8-433f-8e99-967805f3ed56",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f9e09717-1967-41c7-a6de-c8ddd5058874",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyperparameters = {\n",
    "    \"max_length\": 128,\n",
    "    \"emb_dim\": 128,\n",
    "    \"attention_heads\": 4,\n",
    "    \"layers\": 6,\n",
    "    \"dropout\": 0.01,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"epochs\": 100,\n",
    "    \"batch_size\": 4,\n",
    "}\n",
    "\n",
    "model_dirs = {\n",
    "    \"logging\": \"logs\",\n",
    "    \"out\": \"out/model_test\"\n",
    "}\n",
    "\n",
    "model_data = {\n",
    "    \"train_dataset\": train_dataset,\n",
    "    \"eval_dataset\": eval_dataset,\n",
    "    \"data_collator\": data_collator,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9267d84c-8f2d-4f56-8557-0db0cef2b1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gpt2_transformer(hyperparameters, tokenizer, data, dirs):\n",
    "\n",
    "    # define model config and model\n",
    "    config = GPT2Config(\n",
    "        vocab_size = tokenizer.vocab_size,\n",
    "        n_positions = hyperparameters[\"max_length\"], # max seq length\n",
    "        n_embd = hyperparameters[\"emb_dim\"],\n",
    "        n_head = hyperparameters[\"attention_heads\"], \n",
    "        n_layer = hyperparameters[\"layers\"],\n",
    "        dropout = hyperparameters[\"dropout\"],\n",
    "        bos_token_id = tokenizer.bos_token_id,\n",
    "        eos_token_id = tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    model = GPT2LMHeadModel(config)\n",
    "\n",
    "    # define training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir = dirs[\"out\"],\n",
    "        overwrite_output_dir = True,\n",
    "        num_train_epochs = hyperparameters[\"epochs\"],\n",
    "        per_device_train_batch_size = hyperparameters[\"batch_size\"],\n",
    "        save_steps = 1000,\n",
    "        save_total_limit = 5, # maximum number of models to save\n",
    "        learning_rate = hyperparameters[\"learning_rate\"], \n",
    "        #weight_decay=0.01, # You can adjust the weight decay as needed\n",
    "        #warmup_steps=1_000, # Number of warmup steps for learning rate scheduling\n",
    "        logging_dir = dirs[\"logging\"],\n",
    "        logging_steps = 100,\n",
    "        seed = 4711,\n",
    "        evaluation_strategy = \"epoch\",\n",
    "        logging_strategy = \"epoch\"\n",
    "    )\n",
    "\n",
    "    # Create and train  Trainer\n",
    "    trainer = Trainer(\n",
    "        model = model,\n",
    "        args = training_args,\n",
    "        data_collator = data[\"data_collator\"],\n",
    "        train_dataset = data[\"train_dataset\"],\n",
    "        eval_dataset = data[\"eval_dataset\"]\n",
    "    )\n",
    "    \n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e0bf49f-0cc1-46da-ba11-fcde16cab542",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyperparameters = {\n",
    "    \"max_length\": 128,\n",
    "    \"emb_dim\": 128,\n",
    "    \"attention_heads\": 4,\n",
    "    \"layers\": 6,\n",
    "    \"dropout\": 0.01,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"epochs\": 1,\n",
    "    \"batch_size\": 4,\n",
    "}\n",
    "\n",
    "model_dirs = {\n",
    "    \"logging\": \"logs\",\n",
    "    \"out\": \"out/model_test\"\n",
    "}\n",
    "\n",
    "model_data = {\n",
    "    \"train_dataset\": train_dataset,\n",
    "    \"eval_dataset\": eval_dataset,\n",
    "    \"data_collator\": data_collator,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21501de5-15f9-4215-84fb-9e61d68afa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_test = train_gpt2_transformer(\n",
    "    hyperparameters = model_hyperparameters,\n",
    "    tokenizer = tokenizer,\n",
    "    data = model_data,\n",
    "    dirs = model_dirs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f01426a1-4bcc-4463-872a-4dcd53556682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlauten_ext/PyEnv/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='181' max='181' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [181/181 00:05, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.541700</td>\n",
       "      <td>3.195796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=181, training_loss=3.5416782442377417, metrics={'train_runtime': 5.994, 'train_samples_per_second': 120.453, 'train_steps_per_second': 30.197, 'total_flos': 164947034112.0, 'train_loss': 3.5416782442377417, 'epoch': 1.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_test.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eb0e423-9040-478f-a208-03fb23492dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]], device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Bar_None\".split(\" \"), return_tensors=\"pt\")\n",
    "inputs = inputs.to(device)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd442e20-57f1-4f2b-98b6-56add814c340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:122 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 104, 119,  17,  38,   0, 103, 118,  17,  38,   0, 103, 118,  17,\n",
       "          38,   0, 103, 118,  17,  38]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = trainer_test.model.generate(inputs, max_length=20, temperature=0.8)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "904a358d-ee7f-4ac0-9cab-65b19fa6ee97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:122 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 103, 118,   8, 103, 102,  13,  48, 115,   5,  40, 114, 119,  18,\n",
       "           8,  38, 109,  15,  52,  84, 112,  20,  44,  40, 111,  12,   8,  38,\n",
       "         108, 119, 118, 114,  17, 111,  12, 119,  15,  40,  20,  38,  29,  38,\n",
       "         117,  12,  78, 101, 107,  12,  29,  12,  68,  17,  40,  52, 103,  15,\n",
       "          44,  13,  38,  22,  46,  15, 118, 104, 119,  11, 104,  25,  40,  77,\n",
       "          65,  10,  40,  46,   8, 119,  60, 113,  19,  29,  38, 101, 117,  17,\n",
       "          23,  25,  59,  52,  12, 100,  95,  10,  38, 108,  13, 115,  44, 101,\n",
       "         113,  17],\n",
       "        [  0,  94,  44, 101, 111, 119,  15,  52,  65,  38, 103,  22,  17, 101,\n",
       "         116,  42, 113, 116,  13,  38, 114,  44, 115,  44, 101,  41,  13,  25,\n",
       "         102, 116,  25,  42, 112, 119,   5,  44,  12, 102,  15,  29, 109,  10,\n",
       "          10,  10, 105,  15, 112, 119,  26,  13, 107,  12,  59,  48, 101,  44,\n",
       "         115,  64,  38, 110,  12,  19,  32,   0,  46,   2,   8,  19,  40, 111,\n",
       "          92,  26, 104,  17, 103, 106,   8,  11,  38,  69, 112, 118,  10,  29,\n",
       "           6,  56,   8, 112, 106,  15,  19,  52, 104, 119,  42,   0,  55, 104,\n",
       "         119,  18],\n",
       "        [  0, 103,  24,  38, 112, 107,  92,  44,   5,  40,   8,  17,  59, 101,\n",
       "         108,  17,   0,   7,  48, 109, 119,  16, 103, 105,  41,  40,   0,  60,\n",
       "          15,  38, 106,   5, 116,  17,  40, 107,  17,  44, 110, 108, 109,  15,\n",
       "          44, 101, 117,  13,  44,  61,  42, 108,  77,  13,   0, 102,  44, 101,\n",
       "          77,  38, 111,   5,  40, 110,  16,  52, 101, 107,  12,  48,  38,  77,\n",
       "         109,  18,  52, 104,  84,  26, 111, 112, 118,  25,  19, 113,  20,  38,\n",
       "           0,   8,  13,  15, 110,  10,  48,  65, 111, 119, 114, 107, 119,  15,\n",
       "          13,  76]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = trainer_test.model.generate(\n",
    "    input_ids=inputs,\n",
    "    max_length=100,  # maximum length of generated text\n",
    "    do_sample=True,  # enable random sampling\n",
    "    num_return_sequences=3  # number of generated sequences\n",
    ")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc840a6-3c9c-412d-96b9-1485c9977d82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8746cd56-e319-4fab-b761-47c3cc87f6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bar_NonePosition_3/16Position-Triole_2Note-On_76Note-Duration_2Bar_NonePosition_2/16Position-Triole_1Note-On_76Note-Duration_2Bar_NonePosition_2/16Position-Triole_1Note-On_76Note-Duration_2Bar_NonePosition_2/16Position-Triole_1Note-On_76Note-Duration_2'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea991413-13ff-40b5-90a4-c059dca912d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt_models/model1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# trainer.save_model(\"gpt_models/model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7fefd2-15d0-4ea2-9d10-3bd53500f585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e4704a-6743-4b40-aa42-095525742cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08d5ae91-fd1a-4881-a4c2-5b1cecd5735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTE_TYPES_following = {\n",
    "    \"start\": [\"pos\"],\n",
    "    \"start-pos\": [\"pitch\", \"ptriole\"],\n",
    "    \"start-pos-ptriole\": [\"pitch\"],\n",
    "    \"start-pos-pitch\": [\"duration\"],\n",
    "    \"start-pos-ptriole-pitch\": [\"duration\"],\n",
    "    \"start-pos-pitch-duration\": [\"dtriole\"],\n",
    "    \"start-pos-pitch-duration-dtriole\": [],\n",
    "    \"start-pos-ptriole-pitch-duration\": [\"dtriole\"],\n",
    "    \"start-pos-ptriole-pitch-duration-dtriole\": [],\n",
    "}\n",
    "\n",
    "def analyze_token_sequence(seq):\n",
    "    counts = {note_type: 0 for note_type in NOTE_TYPES_following}\n",
    "    current_note_type = \"start\"\n",
    "\n",
    "    for token in seq:\n",
    "\n",
    "        if token_type(token) in NOTE_TYPES_following[current_note_type]:\n",
    "            current_note_type += \"-\" + token_type(token)\n",
    "        else:\n",
    "            counts[current_note_type] += 1\n",
    "            if token_type(token) == \"pos\":\n",
    "                current_note_type = \"start-pos\"\n",
    "            else:\n",
    "                current_note_type = \"start\"\n",
    "    \n",
    "    counts[current_note_type] += 1\n",
    "    return counts\n",
    "\n",
    "def token_type(token):\n",
    "    if token in range(102, 118):\n",
    "        return \"pos\"\n",
    "    elif token in range(1, 37):\n",
    "        return \"pitch\"\n",
    "    elif token in range(118, 120):\n",
    "        return \"ptriole\"\n",
    "    elif token in range(37, 101):\n",
    "        return \"duration\"\n",
    "    elif token == 101:\n",
    "        return \"dtriole\"\n",
    "    elif token == 0:\n",
    "        return \"Bar\"\n",
    "    elif token in range(120, 123):\n",
    "        return \"Bar\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid token: {}\".format(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "190cc9a8-0a7c-4bdc-8212-3b0b15e61352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f90fdc2-75e0-4a03-96a8-0eec0183e715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-ptriole</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-pitch</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-ptriole-pitch</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-pitch-duration</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-pitch-duration-dtriole</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-ptriole-pitch-duration</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-ptriole-pitch-duration-dtriole</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0   1   2\n",
       "start                                     37  30  28\n",
       "start-pos                                  2   9  11\n",
       "start-pos-ptriole                          1   1   1\n",
       "start-pos-pitch                            8   8   2\n",
       "start-pos-ptriole-pitch                    3   3   3\n",
       "start-pos-pitch-duration                   6   3   9\n",
       "start-pos-pitch-duration-dtriole           1   0   2\n",
       "start-pos-ptriole-pitch-duration           0   2   0\n",
       "start-pos-ptriole-pitch-duration-dtriole   0   0   0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {}\n",
    "for idx, res in enumerate(output):\n",
    "    an = analyze_token_sequence(res)\n",
    "    dic[idx] = an\n",
    "\n",
    "pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc632851-ab58-4dc3-9305-6acd58afb4ae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sequential Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "52807e76-37dc-41e6-91c2-ebff97c93534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define GPT-2 model architecture\n",
    "config = GPT2Config(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    n_positions=128, # max seq length\n",
    "    n_embd=128,\n",
    "    n_head=4, \n",
    "    n_layer=6,\n",
    "    dropout=0.01 \n",
    ")\n",
    "model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "55f65bc4-e736-4c58-9571-fc4d16a1a131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"dropout\": 0.01,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_embd\": 128,\n",
       "  \"n_head\": 4,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 6,\n",
       "  \"n_positions\": 128,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"transformers_version\": \"4.27.4\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 120\n",
       "}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "28f71513-e8f2-4985-9ea2-d89d3140386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"out\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=30,\n",
    "    per_device_train_batch_size=4, # You can adjust the batch size per device as needed\n",
    "    save_steps=1000,\n",
    "    save_total_limit=5, # maximum number of models to save\n",
    "    learning_rate=1e-4, # You can adjust the learning rate as needed\n",
    "    #weight_decay=0.01, # You can adjust the weight decay as needed\n",
    "    #warmup_steps=1_000, # Number of warmup steps for learning rate scheduling\n",
    "    logging_dir='logs', # Directory to save the training logs\n",
    "    logging_steps=100, # Number of steps to log training progress\n",
    "    seed=4711, # Set a seed for reproducibility\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# Create and train  Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f36c7e8a-36cb-4317-9e7c-0314f6477d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5430' max='5430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5430/5430 02:42, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.362900</td>\n",
       "      <td>2.717453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.422900</td>\n",
       "      <td>2.264060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.097500</td>\n",
       "      <td>2.017088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.901100</td>\n",
       "      <td>1.843353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.766000</td>\n",
       "      <td>1.729854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.676300</td>\n",
       "      <td>1.656317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.608000</td>\n",
       "      <td>1.599752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.565500</td>\n",
       "      <td>1.550471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.520200</td>\n",
       "      <td>1.523684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.495900</td>\n",
       "      <td>1.499394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.469800</td>\n",
       "      <td>1.486028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.445800</td>\n",
       "      <td>1.458932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.425900</td>\n",
       "      <td>1.445532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.415400</td>\n",
       "      <td>1.436940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.398100</td>\n",
       "      <td>1.430205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.383500</td>\n",
       "      <td>1.413540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.375700</td>\n",
       "      <td>1.419358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.362200</td>\n",
       "      <td>1.407698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.349400</td>\n",
       "      <td>1.404736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.342800</td>\n",
       "      <td>1.391201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.336900</td>\n",
       "      <td>1.386473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.329800</td>\n",
       "      <td>1.382916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.321400</td>\n",
       "      <td>1.385702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.315100</td>\n",
       "      <td>1.380314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.305400</td>\n",
       "      <td>1.373040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.300800</td>\n",
       "      <td>1.375209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.298300</td>\n",
       "      <td>1.376242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.292800</td>\n",
       "      <td>1.367407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.290100</td>\n",
       "      <td>1.368731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.281400</td>\n",
       "      <td>1.368672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "training = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c6e05523-641e-4d5f-9d1f-95526efd8a8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5430, training_loss=1.5485621555953615, metrics={'train_runtime': 162.8006, 'train_samples_per_second': 133.046, 'train_steps_per_second': 33.354, 'total_flos': 4948411023360.0, 'train_loss': 1.5485621555953615, 'epoch': 30.0})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3979eff4-dd78-4c23-89bc-b384345a7207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]], device='cuda:0')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Bar_None\".split(\" \"), return_tensors=\"pt\")\n",
    "inputs = inputs.to(device)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e313a9b-1d8f-4bd6-bdfa-9378e1a62036",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Variante A ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f6a7a73-af18-41e0-af16-13b92be730eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 120])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(inputs)\n",
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85095d2a-ed8f-4343-8e54-522c848fe4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2547, -2.1192, -7.2306, -2.7882, -7.2182, -1.6130, -3.2042,\n",
       "          -7.0037, -1.7453, -3.5268, -1.4314, -3.0444, -2.2273, -1.1538,\n",
       "          -3.5951, -1.4390, -3.5149, -1.0911, -3.2377, -3.2269, -2.1793,\n",
       "          -7.2091, -1.7342, -3.2474, -3.2308, -2.2438, -7.3862, -2.9835,\n",
       "          -7.5360, -3.4471, -7.1169, -7.0729, -3.7748, -7.2140, -7.0705,\n",
       "          -7.2860, -7.2197, -3.6261, -0.6181, -7.1656, -0.8093, -7.2236,\n",
       "          -3.1740, -7.2032, -1.3843, -7.2304, -2.8611, -7.3672, -2.5701,\n",
       "          -7.2789, -3.4928, -7.2448, -2.5277, -7.3382, -2.8937, -7.1164,\n",
       "          -3.2698, -7.4626, -3.0290, -7.2825, -4.7054, -7.3309, -3.6156,\n",
       "          -3.8380, -3.5813, -4.7972, -3.9706, -7.2940, -1.2369, -7.3213,\n",
       "          -3.5374, -4.9148, -4.2818, -7.1624, -4.3432, -7.1656, -2.3467,\n",
       "          -7.1572, -3.5976, -4.0147, -3.6525, -7.1724, -7.3088, -7.2978,\n",
       "          -4.0406, -7.5917, -7.1573, -7.2811, -7.2571, -7.2548, -7.3264,\n",
       "          -7.1548, -2.0736, -7.1610, -7.2467, -7.2848, -7.4697, -7.2878,\n",
       "          -7.2136, -7.3570, -3.1832, -0.1810,  3.9298,  4.7511,  4.7234,\n",
       "           4.2499,  4.4124,  4.7379,  4.5904,  3.8389,  3.9865,  4.3778,\n",
       "           4.3289,  3.6646,  3.8399,  4.3382,  4.3000,  3.7824, -1.0074,\n",
       "          -1.2358]]], device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61b43a14-762f-4f18-81de-a5fb710887a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[17]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temperature value\n",
    "temperature = 13\n",
    "\n",
    "# Convert logits to probabilities using softmax with temperature\n",
    "probs = F.softmax(outputs.logits / temperature, dim=-1)\n",
    "\n",
    "# Sample a token from the probability distribution for each position in the sequence\n",
    "predicted_tokens = torch.multinomial(probs.view(-1, probs.shape[-1]), num_samples=1).view(*probs.shape[:-1])\n",
    "predicted_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1bba3c96-7bf2-4fef-9ebe-0275f64a5bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Note-On_76'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(predicted_tokens[0], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa891493-c9a9-4e56-99d5-b54d65ceb336",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Variante B ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "578a0c47-56cf-4234-b3e7-74b40c7ba585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 104, 119,   8,  38, 106,   8,  44, 101, 107, 118,   8,  44, 101,\n",
       "         108, 119,   8,  38, 110,   8]], device='cuda:0')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#outputs = model.generate(inputs, max_length=100, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "outputs = model.generate(inputs, max_length=20, temperature=0.8)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eb63a771-626f-443f-b9e9-921d213905f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bar_NonePosition_3/16Position-Triole_2Note-On_67Note-Duration_2Position_5/16Note-On_67Note-Duration_8Note-Duration_triolePosition_6/16Position-Triole_1Note-On_67Note-Duration_8Note-Duration_triolePosition_7/16Position-Triole_2Note-On_67Note-Duration_2Position_9/16Note-On_67'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6b28662-9f31-4d78-9124-f2b15f3b2a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"gpt_models/model1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cf8d61-d82c-4072-a10c-3872177d8484",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e416491a-3475-4949-b291-9962e141362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"gpt_models/model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21426bb5-d3bc-41b3-b143-7dd66081cbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Bar_None\".split(\" \"), return_tensors=\"pt\")\n",
    "inputs = inputs.to(\"cpu\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ecb58a9-129b-49bc-880a-8e9907217026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 103, 118,  10,  40, 105,  10,  44, 101, 107, 118,  10,  38, 109,\n",
       "          13,  38, 110,  10,  44, 101]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.generate(inputs, max_length=20, temperature=0.8)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f5c2125-43f0-4ce6-910a-945e505c0948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 105,  25,  38, 106,  24,  38, 107,  22,  42, 110,  20,  40, 113,\n",
       "          22,  38, 114,  22,  68, 101,   0, 105,  22,  38, 106,  22,  38, 107,\n",
       "          24,  40, 109,  22,  38, 109,  22,  38, 107,  24,  40, 109,  22,  40,\n",
       "         109,  15,  38, 109,  20,  38, 109,  20,  38, 109,  22,  38, 109,  24,\n",
       "          40, 113,  20,  42, 113,  20,  38,   0, 109,  22,  38, 101,   0, 103,\n",
       "          22,  40, 109,  20,  38, 101,   0, 105,  20,  38, 101,   0, 105,  22,\n",
       "          42, 113,  17,  38, 109,  22,  38,   0, 105,  24,  42, 113,  22,  38,\n",
       "         101,   0],\n",
       "        [  0, 100,  22,  52,   0, 105,  22,  40, 107,  17,  44, 111,  15,  44,\n",
       "         115,  13,  44,   0, 103,  15,  44, 107,  13,  76,   0, 105,  17,  44,\n",
       "         111,  20,  46, 115,  17,  44, 117,  20,  40, 113,  17,  44, 117,  20,\n",
       "          44, 117,  20,  44,   0, 103,  22,  44,   0, 103,  15,  44, 107,   1,\n",
       "          44, 111,  17,  44,   0, 103,  22,  44, 115,  13,  44,   0, 103,  10,\n",
       "          44,   0, 103,  13,  52, 111,  22,  44,   0, 103,  17,  44, 109,  20,\n",
       "          52, 111,   8,  44, 109,  22,  46, 115,  13,  52, 101, 112, 119,  10,\n",
       "          40, 112],\n",
       "        [  0, 105,  17,  52, 101, 109,  17,  44, 101, 111, 118,  13,  52, 101,\n",
       "         113,  12,  44, 101,   0, 105,  17,  46, 117,  13,  52, 101,   0, 105,\n",
       "          13,  44, 109,  10,  44, 101, 107, 118,  15,  38, 107, 118,  13,  38,\n",
       "         107, 118,  15,  38, 107, 118,  17,  38, 107, 118,  10,  44, 101, 107,\n",
       "         118,  15,  44, 101, 107, 118,  15,  38, 104, 119,  15,  38, 107, 118,\n",
       "          17,  40, 107, 118,  17,  38, 107, 118,  17,  38, 107, 118,  13,  44,\n",
       "         101, 107, 118,  10,  38, 107, 118,  17,  38, 107, 118,  13,  38, 107,\n",
       "         118,  17]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.generate(\n",
    "    input_ids=inputs,\n",
    "    max_length=100,  # maximum length of generated text\n",
    "    do_sample=True,  # enable random sampling\n",
    "    num_return_sequences=3  # number of generated sequences\n",
    ")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60ea0b92-fe18-44d5-8f53-40b79e2bdf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-ptriole</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-pitch</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-ptriole-pitch</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-pitch-duration</th>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-pitch-duration-dtriole</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-ptriole-pitch-duration</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-ptriole-pitch-duration-dtriole</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0   1   2\n",
       "start                                      2   5   1\n",
       "start-pos                                  0   1   0\n",
       "start-pos-ptriole                          0   0   0\n",
       "start-pos-pitch                            0   0   0\n",
       "start-pos-ptriole-pitch                    0   0   1\n",
       "start-pos-pitch-duration                  24  26   2\n",
       "start-pos-pitch-duration-dtriole           5   1   5\n",
       "start-pos-ptriole-pitch-duration           0   1  12\n",
       "start-pos-ptriole-pitch-duration-dtriole   0   0   4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {}\n",
    "for idx, res in enumerate(output):\n",
    "    an = analyze_token_sequence(res)\n",
    "    dic[idx] = an\n",
    "\n",
    "pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1732cd56-308b-4779-b526-a5a1900d7be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 103,\n",
       " 118,\n",
       " 10,\n",
       " 40,\n",
       " 105,\n",
       " 10,\n",
       " 44,\n",
       " 101,\n",
       " 107,\n",
       " 118,\n",
       " 10,\n",
       " 38,\n",
       " 109,\n",
       " 13,\n",
       " 38,\n",
       " 110,\n",
       " 10,\n",
       " 44,\n",
       " 101]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [tensor.item() for tensor in list(outputs[0])]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f56d3c-573d-4bc2-a7b8-2b351a2cc8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [pipenv: PyEnv]",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
