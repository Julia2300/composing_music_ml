{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22ff8f9-cea1-42a2-8792-31b451e99e50",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from model_functions import PaddedDataset, trainer_gpt2_transformer, analyze_token_sequence\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import GPT2Config, GPT2Tokenizer, GPT2LMHeadModel, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    "\n",
    "\n",
    "PATH_VOCAB = \"../0_data/5_vocabs\"\n",
    "PATH_WORD_DATA = \"../0_data/6_word_data\"\n",
    "PATH_MODELS = \"../0_data/7_models\"\n",
    "PATH_MODELS_LOSS = \"../0_data/7_models/loss\"\n",
    "PATH_MODELS_CONFIG = \"../0_data/7_models/config\"\n",
    "\n",
    "for path in [PATH_MODELS, PATH_MODELS_LOSS, PATH_MODELS_CONFIG]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f9159c4-96f5-4ec0-b354-ca07f7c23b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a0de7b-c342-4326-b1dd-b55e0c390cfc",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21991d5a-0ae8-4538-a265-ae220545b340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 803\n",
      "90% at:      722\n",
      "\n",
      "Example data point: Bar_None Position_3/16 Note-On_76 Note-Duration_2 Position_4\n"
     ]
    }
   ],
   "source": [
    "with open('data_words.json', 'r') as fp:\n",
    "    json_data = json.load(fp)\n",
    "\n",
    "song_list = []\n",
    "for song in json_data:\n",
    "    song_list.append(json_data[song])\n",
    "\n",
    "data = [\" \".join(song) for song in song_list]\n",
    "\n",
    "split_train_test = int(0.9*len(data))\n",
    "print(\"Data length:\", len(data))\n",
    "print(\"90% at:     \", split_train_test)\n",
    "print()\n",
    "print(\"Example data point:\", data[0][:60])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6327f311-3851-4e98-a3de-0571bb8d7bad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tokeinzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0b984b6-7c64-4f76-bfa8-48e2f715494f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  120\n",
      "PAD token:  120\n",
      "BOS token:  121\n",
      "EOS token:  122\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer(\n",
    "    vocab_file=\"vocab.json\", \n",
    "    merges_file=\"merges.txt\")\n",
    "\n",
    "tokenizer.add_special_tokens({'pad_token': 'PAD', 'bos_token': 'BOS', 'eos_token': 'EOS',})\n",
    "\n",
    "print(\"vocab size: \", tokenizer.vocab_size)\n",
    "print(\"PAD token: \", tokenizer.pad_token_id)\n",
    "print(\"BOS token: \", tokenizer.bos_token_id)\n",
    "print(\"EOS token: \", tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de3950d-0cb8-433f-8e99-967805f3ed56",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9267d84c-8f2d-4f56-8557-0db0cef2b1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>max_length</th>\n",
       "      <th>emb_dim</th>\n",
       "      <th>attention_heads</th>\n",
       "      <th>layers</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>ran</th>\n",
       "      <th>runtime</th>\n",
       "      <th>runtime_min</th>\n",
       "      <th>min_loss</th>\n",
       "      <th>at_epoch</th>\n",
       "      <th>incorrect_notes</th>\n",
       "      <th>correct_notes</th>\n",
       "      <th>correct_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_short_small_50</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>185.8307</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.162286</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_short_medium_50</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>304.2706</td>\n",
       "      <td>5.07</td>\n",
       "      <td>1.208278</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_short_large_50</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>559.9953</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1.841974</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4_middle_small_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>241.443</td>\n",
       "      <td>4.02</td>\n",
       "      <td>1.09383</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5_middle_medium_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>614.6323</td>\n",
       "      <td>10.24</td>\n",
       "      <td>1.120662</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6_middle_large_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>2237.4356</td>\n",
       "      <td>37.29</td>\n",
       "      <td>1.883723</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7_long_small_50</td>\n",
       "      <td>2048</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>482.1712</td>\n",
       "      <td>8.04</td>\n",
       "      <td>1.120337</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8_long_medium_50</td>\n",
       "      <td>2048</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>1494.6219</td>\n",
       "      <td>24.91</td>\n",
       "      <td>1.156429</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9_long_large_50</td>\n",
       "      <td>2048</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>too big - cuda error</td>\n",
       "      <td>too big - cuda error</td>\n",
       "      <td>too big - cuda error</td>\n",
       "      <td>too big - cuda error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  max_length  emb_dim  attention_heads  layers  dropout   \n",
       "0    1_short_small_50         256      128                2       3     0.01  \\\n",
       "1   2_short_medium_50         256      256                4       6     0.01   \n",
       "2    3_short_large_50         256      512                8      12     0.01   \n",
       "3   4_middle_small_50        1024      128                2       3     0.01   \n",
       "4  5_middle_medium_50        1024      256                4       6     0.01   \n",
       "5   6_middle_large_50        1024      512                8      12     0.01   \n",
       "6     7_long_small_50        2048      128                2       3     0.01   \n",
       "7    8_long_medium_50        2048      256                4       6     0.01   \n",
       "8     9_long_large_50        2048      512                8      12     0.01   \n",
       "\n",
       "   learning_rate  epochs  batch_size  ran               runtime   \n",
       "0          0.001      50           4  yes              185.8307  \\\n",
       "1          0.001      50           4  yes              304.2706   \n",
       "2          0.001      50           4  yes              559.9953   \n",
       "3          0.001      50           4  yes               241.443   \n",
       "4          0.001      50           4  yes              614.6323   \n",
       "5          0.001      50           4  yes             2237.4356   \n",
       "6          0.001      50           4  yes              482.1712   \n",
       "7          0.001      50           4  yes             1494.6219   \n",
       "8          0.001      50           4  yes  too big - cuda error   \n",
       "\n",
       "            runtime_min              min_loss              at_epoch   \n",
       "0                   3.1              1.162286                    46  \\\n",
       "1                  5.07              1.208278                    30   \n",
       "2                  9.33              1.841974                    48   \n",
       "3                  4.02               1.09383                    50   \n",
       "4                 10.24              1.120662                    37   \n",
       "5                 37.29              1.883723                    49   \n",
       "6                  8.04              1.120337                    49   \n",
       "7                 24.91              1.156429                    35   \n",
       "8  too big - cuda error  too big - cuda error  too big - cuda error   \n",
       "\n",
       "   incorrect_notes  correct_notes  correct_rate  \n",
       "0              NaN            NaN           NaN  \n",
       "1              NaN            NaN           NaN  \n",
       "2              NaN            NaN           NaN  \n",
       "3              NaN            NaN           NaN  \n",
       "4              NaN            NaN           NaN  \n",
       "5              NaN            NaN           NaN  \n",
       "6              NaN            NaN           NaN  \n",
       "7              NaN            NaN           NaN  \n",
       "8              NaN            NaN           NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = pd.read_excel(\"model_stats_preprocessed.xlsx\", index_col=\"Unnamed: 0\")\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5acc8dec-1f5c-4751-a229-396004dea99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>max_length</th>\n",
       "      <th>emb_dim</th>\n",
       "      <th>attention_heads</th>\n",
       "      <th>layers</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>ran</th>\n",
       "      <th>runtime</th>\n",
       "      <th>runtime_min</th>\n",
       "      <th>min_loss</th>\n",
       "      <th>at_epoch</th>\n",
       "      <th>incorrect_notes</th>\n",
       "      <th>correct_notes</th>\n",
       "      <th>correct_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_short_small_50</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>185.8307</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.162286</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_short_medium_50</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>304.2706</td>\n",
       "      <td>5.07</td>\n",
       "      <td>1.208278</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_short_large_50</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>559.9953</td>\n",
       "      <td>9.33</td>\n",
       "      <td>1.841974</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4_middle_small_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>241.443</td>\n",
       "      <td>4.02</td>\n",
       "      <td>1.09383</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5_middle_medium_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>614.6323</td>\n",
       "      <td>10.24</td>\n",
       "      <td>1.120662</td>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6_middle_large_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>2237.4356</td>\n",
       "      <td>37.29</td>\n",
       "      <td>1.883723</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7_long_small_50</td>\n",
       "      <td>2048</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>482.1712</td>\n",
       "      <td>8.04</td>\n",
       "      <td>1.120337</td>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8_long_medium_50</td>\n",
       "      <td>2048</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>1494.6219</td>\n",
       "      <td>24.91</td>\n",
       "      <td>1.156429</td>\n",
       "      <td>35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9_long_large_50</td>\n",
       "      <td>2048</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>too big - cuda error</td>\n",
       "      <td>too big - cuda error</td>\n",
       "      <td>too big - cuda error</td>\n",
       "      <td>too big - cuda error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  max_length  emb_dim  attention_heads  layers  dropout   \n",
       "0    1_short_small_50         256      128                2       3     0.01  \\\n",
       "1   2_short_medium_50         256      256                4       6     0.01   \n",
       "2    3_short_large_50         256      512                8      12     0.01   \n",
       "3   4_middle_small_50        1024      128                2       3     0.01   \n",
       "4  5_middle_medium_50        1024      256                4       6     0.01   \n",
       "5   6_middle_large_50        1024      512                8      12     0.01   \n",
       "6     7_long_small_50        2048      128                2       3     0.01   \n",
       "7    8_long_medium_50        2048      256                4       6     0.01   \n",
       "8     9_long_large_50        2048      512                8      12     0.01   \n",
       "\n",
       "   learning_rate  epochs  batch_size  ran               runtime   \n",
       "0          0.001      50           4  yes              185.8307  \\\n",
       "1          0.001      50           4  yes              304.2706   \n",
       "2          0.001      50           4  yes              559.9953   \n",
       "3          0.001      50           4  yes               241.443   \n",
       "4          0.001      50           4  yes              614.6323   \n",
       "5          0.001      50           4  yes             2237.4356   \n",
       "6          0.001      50           4  yes              482.1712   \n",
       "7          0.001      50           4  yes             1494.6219   \n",
       "8          0.001      50           4  yes  too big - cuda error   \n",
       "\n",
       "            runtime_min              min_loss              at_epoch   \n",
       "0                   3.1              1.162286                    46  \\\n",
       "1                  5.07              1.208278                    30   \n",
       "2                  9.33              1.841974                    48   \n",
       "3                  4.02               1.09383                    50   \n",
       "4                 10.24              1.120662                    37   \n",
       "5                 37.29              1.883723                    49   \n",
       "6                  8.04              1.120337                    49   \n",
       "7                 24.91              1.156429                    35   \n",
       "8  too big - cuda error  too big - cuda error  too big - cuda error   \n",
       "\n",
       "   incorrect_notes  correct_notes  correct_rate  \n",
       "0              NaN            NaN           NaN  \n",
       "1              NaN            NaN           NaN  \n",
       "2              NaN            NaN           NaN  \n",
       "3              NaN            NaN           NaN  \n",
       "4              NaN            NaN           NaN  \n",
       "5              NaN            NaN           NaN  \n",
       "6              NaN            NaN           NaN  \n",
       "7              NaN            NaN           NaN  \n",
       "8              NaN            NaN           NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = []\n",
    "\n",
    "for index, row in model_df.iterrows():\n",
    "    \n",
    "    # only run models that not ran yet\n",
    "    if row[\"ran\"] == \"yes\":\n",
    "        continue\n",
    "    \n",
    "    # create model name directories\n",
    "    model_name = row[\"name\"]\n",
    "    model_dirs = {\n",
    "        \"logging\": f\"logs/{model_name}\",\n",
    "        \"out\": f\"out/{model_name}\"\n",
    "    }\n",
    "    for key in model_dirs:\n",
    "        if not os.path.exists(model_dirs[key]):\n",
    "            os.makedirs(model_dirs[key])\n",
    "    \n",
    "    # save hyperparameters as dictionary\n",
    "    model_hyperparameters = {\n",
    "        \"max_length\": row[\"max_length\"],\n",
    "        \"emb_dim\": row[\"emb_dim\"],\n",
    "        \"attention_heads\": row[\"attention_heads\"],\n",
    "        \"layers\": row[\"layers\"],\n",
    "        \"dropout\": row[\"dropout\"],\n",
    "        \"learning_rate\": row[\"learning_rate\"],\n",
    "        \"epochs\": row[\"epochs\"],\n",
    "        \"batch_size\": row[\"batch_size\"],\n",
    "    }\n",
    "    \n",
    "    # create datasets and define data collator\n",
    "    train_dataset = PaddedDataset(tokenizer=tokenizer, data=data[:split_train_test], max_length=row[\"max_length\"])\n",
    "    eval_dataset = PaddedDataset(tokenizer=tokenizer, data=data[split_train_test:], max_length=row[\"max_length\"])\n",
    "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "    model_data = {\n",
    "        \"train_dataset\": train_dataset,\n",
    "        \"eval_dataset\": eval_dataset,\n",
    "        \"data_collator\": data_collator,\n",
    "    }\n",
    "    \n",
    "    # create and train model trainer\n",
    "    trainer = trainer_gpt2_transformer(\n",
    "        hyperparameters = model_hyperparameters,\n",
    "        tokenizer = tokenizer,\n",
    "        data = model_data,\n",
    "        dirs = model_dirs,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    \n",
    "    # save runtime and model loss\n",
    "    log_hist = trainer.state.log_history\n",
    "    eval_loss = [log_hist[i][\"eval_loss\"] for i in range(1,len(log_hist),2)]\n",
    "    train_loss = [log_hist[i][\"loss\"] for i in range(0,len(log_hist)-1,2)]\n",
    "    runtime = log_hist[-1][\"train_runtime\"]\n",
    "    \n",
    "    model_df.at[index,\"runtime\"] = runtime\n",
    "    model_df.at[index,\"runtime_min\"] = (runtime/60).__round__(2)\n",
    "    model_df.at[index,\"min_loss\"] = min(eval_loss)\n",
    "    model_df.at[index,\"at_epoch\"] = np.argmin(eval_loss) + 1\n",
    "\n",
    "    # show loss plot\n",
    "    plt.plot(train_loss, color=\"blue\")\n",
    "    plt.plot(eval_loss, color=\"orange\")\n",
    "    plt.savefig(f\"{model_dirs['logging']}/loss_graph_{model_name}.jpg\")\n",
    "    plt.show()\n",
    "    \n",
    "    # save model and set ran to yes\n",
    "    trainer.save_model(f\"{model_dirs['out']}/end_version\")\n",
    "    model_df.at[index,\"ran\"] = \"yes\"\n",
    "    \n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84f0b777-7f33-4240-a67b-2ad024a8ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.to_excel(\"model_stats.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc632851-ab58-4dc3-9305-6acd58afb4ae",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Sequential Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4952b63-2f7d-48ac-9c96-808f8fa42e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets and data collator\n",
    "train_dataset = PaddedDataset(tokenizer=tokenizer, data=data[:split_train_test], max_length=32)\n",
    "eval_dataset = PaddedDataset(tokenizer=tokenizer, data=data[split_train_test:], max_length=32)\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52807e76-37dc-41e6-91c2-ebff97c93534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define GPT-2 model architecture\n",
    "config = GPT2Config(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    n_positions=128, # max seq length\n",
    "    n_embd=128,\n",
    "    n_head=4, \n",
    "    n_layer=6,\n",
    "    dropout=0.01 \n",
    ")\n",
    "model = GPT2LMHeadModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28f71513-e8f2-4985-9ea2-d89d3140386e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlauten_ext/PyEnv/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5430' max='5430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5430/5430 02:47, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.346700</td>\n",
       "      <td>2.700208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.412300</td>\n",
       "      <td>2.259674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.096000</td>\n",
       "      <td>2.041030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.926700</td>\n",
       "      <td>1.881823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.795400</td>\n",
       "      <td>1.773080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.702600</td>\n",
       "      <td>1.682822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.630400</td>\n",
       "      <td>1.613042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.581100</td>\n",
       "      <td>1.569922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.534600</td>\n",
       "      <td>1.538607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.504600</td>\n",
       "      <td>1.513601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.474300</td>\n",
       "      <td>1.487351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.458100</td>\n",
       "      <td>1.476995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.435000</td>\n",
       "      <td>1.451662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.420400</td>\n",
       "      <td>1.438760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.405300</td>\n",
       "      <td>1.436790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.391500</td>\n",
       "      <td>1.425632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>1.425141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.365100</td>\n",
       "      <td>1.410937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.356600</td>\n",
       "      <td>1.409747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.346400</td>\n",
       "      <td>1.393651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.339300</td>\n",
       "      <td>1.399441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.332800</td>\n",
       "      <td>1.385703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.321800</td>\n",
       "      <td>1.386798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.316600</td>\n",
       "      <td>1.377830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.309100</td>\n",
       "      <td>1.378455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.302200</td>\n",
       "      <td>1.378031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.300500</td>\n",
       "      <td>1.377607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.296600</td>\n",
       "      <td>1.373922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.292100</td>\n",
       "      <td>1.375411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.284000</td>\n",
       "      <td>1.374813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5430, training_loss=1.5551064085565218, metrics={'train_runtime': 167.7591, 'train_samples_per_second': 129.114, 'train_steps_per_second': 32.368, 'total_flos': 4948411023360.0, 'train_loss': 1.5551064085565218, 'epoch': 30.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_out\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=30,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=5,\n",
    "    learning_rate=1e-4,\n",
    "    #weight_decay=0.01,\n",
    "    #warmup_steps=1_000,\n",
    "    logging_dir=\"test_log\",\n",
    "    logging_steps=100,\n",
    "    seed=4711,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# create and train Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "training = trainer.train()\n",
    "training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8a1426f-1498-4592-a446-c7b2125426f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seconds:  167.7591\n",
      "Minutes:  2.8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_hist = trainer.state.log_history\n",
    "eval_loss = [log_hist[i][\"eval_loss\"] for i in range(1,len(log_hist),2)]\n",
    "train_loss = [log_hist[i][\"loss\"] for i in range(0,len(log_hist)-1,2)]\n",
    "runtime = log_hist[-1][\"train_runtime\"]\n",
    "\n",
    "print(\"Seconds: \", runtime)\n",
    "print(\"Minutes: \", (runtime/60).__round__(2))\n",
    "\n",
    "plt.plot(train_loss, color=\"blue\")\n",
    "plt.plot(eval_loss, color=\"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87419cdb-a3c2-46fd-b244-9b50df9b0a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 103, 118,   8,  40, 105,   8,  44, 101, 107, 118,   8,  44, 101,\n",
       "         108, 119,   8,  44, 101, 111]], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Bar_None\".split(\" \"), return_tensors=\"pt\")\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "#outputs = model.generate(inputs, max_length=100, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "outputs = model.generate(inputs, max_length=20, temperature=0.8)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcc8cd82-2be6-49d3-9b49-a843d08fa0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bar_NonePosition_2/16Position-Triole_1Note-On_67Note-Duration_4Position_4/16Note-On_67Note-Duration_8Note-Duration_triolePosition_6/16Position-Triole_1Note-On_67Note-Duration_8Note-Duration_triolePosition_7/16Position-Triole_2Note-On_67Note-Duration_8Note-Duration_triolePosition_10/16'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(outputs[0], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "498a70a6-3423-4e51-a006-320fbfec019f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.save_model(\"gpt_models/model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e313a9b-1d8f-4bd6-bdfa-9378e1a62036",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Andere Variante ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f6a7a73-af18-41e0-af16-13b92be730eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 120])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(inputs)\n",
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85095d2a-ed8f-4343-8e54-522c848fe4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1162, -2.1350, -3.5313, -1.9780, -3.5414, -1.5776, -1.8704,\n",
       "          -3.5441, -1.1535, -2.6672, -0.8764, -2.2812, -1.6335, -0.8708,\n",
       "          -2.7905, -1.4720, -2.4843, -0.5825, -2.0775, -2.7744, -1.5724,\n",
       "          -3.7235, -1.8095, -2.4802, -2.3428, -2.3748, -3.2765, -2.9800,\n",
       "          -3.1671, -2.6769, -3.6342, -3.3965, -2.9433, -3.3021, -3.6102,\n",
       "          -3.8760, -3.8078, -2.8941, -0.2965, -3.4592, -0.6409, -3.7882,\n",
       "          -1.4499, -3.6240, -0.8940, -3.3144, -1.9948, -3.0505, -2.1582,\n",
       "          -3.2950, -2.2917, -3.4952, -1.5516, -3.7166, -2.3756, -3.3413,\n",
       "          -2.5331, -3.7758, -2.4212, -3.4614, -2.8825, -3.7335, -2.9825,\n",
       "          -2.8619, -2.9172, -3.3198, -3.0439, -2.9400, -1.7772, -3.4107,\n",
       "          -3.0528, -3.1332, -3.2200, -3.2291, -2.9769, -3.1939, -1.9817,\n",
       "          -2.9937, -2.8389, -3.1996, -2.9903, -2.9885, -3.7754, -3.6936,\n",
       "          -3.1062, -3.3149, -3.9010, -3.4983, -3.7158, -3.4427, -3.5639,\n",
       "          -3.5325, -1.8639, -3.7709, -3.4870, -3.2223, -3.6571, -3.4250,\n",
       "          -3.6030, -3.3400, -2.2445,  0.1584,  3.4136,  4.2250,  4.2018,\n",
       "           3.7291,  3.9138,  4.1381,  4.0495,  3.2906,  3.4570,  3.8709,\n",
       "           3.7553,  3.1699,  3.3294,  3.8238,  3.7216,  3.2188, -0.7025,\n",
       "          -0.8708]]], device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61b43a14-762f-4f18-81de-a5fb710887a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temperature value\n",
    "temperature = 13\n",
    "\n",
    "# Convert logits to probabilities using softmax with temperature\n",
    "probs = F.softmax(outputs.logits / temperature, dim=-1)\n",
    "\n",
    "# Sample a token from the probability distribution for each position in the sequence\n",
    "predicted_tokens = torch.multinomial(probs.view(-1, probs.shape[-1]), num_samples=1).view(*probs.shape[:-1])\n",
    "predicted_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bba3c96-7bf2-4fef-9ebe-0275f64a5bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Note-On_83'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(predicted_tokens[0], skip_special_tokens=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MusicAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
