{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f97d2f-6ac1-4348-8876-690002b854db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_functions import analyze_token_sequence, predict, write_midi, get_token_flags\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Config, GPT2Tokenizer, GPT2LMHeadModel, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    "\n",
    "PATH_VOCAB = \"../0_data/5_vocabs\"\n",
    "PATH_MODELS = \"../0_data/7_models\"\n",
    "PATH_MODELS_CONFIG = \"../0_data/7_models/config\"\n",
    "PATH_PRED = \"../0_data/8_predictions\"\n",
    "PATH_TOKENS = \"../0_data/8_predictions/tokens\"\n",
    "PATH_MIDI = \"../0_data/8_predictions/midi\"\n",
    "\n",
    "for path in [PATH_PRED, PATH_TOKENS, PATH_MIDI]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbfd68e1-0b3f-480c-91df-5934fa5e91b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_configs = {\n",
    "    \"a1\" : {\n",
    "        \"pitch_range\": 128,\n",
    "        \"duration_steps\": 64,\n",
    "        \"triole_tokens\": False,\n",
    "    },\n",
    "    \"a2\" : {\n",
    "        \"pitch_range\": 128,\n",
    "        \"duration_steps\": 64,\n",
    "        \"triole_tokens\": True,\n",
    "    },\n",
    "    \"a3\" : {\n",
    "        \"pitch_range\": 128,\n",
    "        \"duration_steps\": 32,\n",
    "        \"triole_tokens\": False,\n",
    "    },\n",
    "    \"b\" : {\n",
    "        \"pitch_range\": 128,\n",
    "        \"duration_steps\": 64,\n",
    "        \"triole_tokens\": False,\n",
    "    },\n",
    "    \"c\" : {\n",
    "        \"pitch_range\": 36,\n",
    "        \"duration_steps\": 64,\n",
    "        \"triole_tokens\": False,\n",
    "    },\n",
    "    \"d\" : {\n",
    "        \"pitch_range\": 36,\n",
    "        \"duration_steps\": 32,\n",
    "        \"triole_tokens\": True,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1befc7-5ced-4b36-b13d-b1bb9778d663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>max_length</th>\n",
       "      <th>emb_dim</th>\n",
       "      <th>attention_heads</th>\n",
       "      <th>layers</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>ran</th>\n",
       "      <th>runtime</th>\n",
       "      <th>runtime_min</th>\n",
       "      <th>min_loss</th>\n",
       "      <th>at_epoch</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>incorrect_notes</th>\n",
       "      <th>correct_notes</th>\n",
       "      <th>correct_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>717.6662</td>\n",
       "      <td>11.96</td>\n",
       "      <td>1.373842</td>\n",
       "      <td>42</td>\n",
       "      <td>423.106567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>716.0189</td>\n",
       "      <td>11.93</td>\n",
       "      <td>1.140858</td>\n",
       "      <td>49</td>\n",
       "      <td>472.513916</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>696.7114</td>\n",
       "      <td>11.61</td>\n",
       "      <td>1.342281</td>\n",
       "      <td>34</td>\n",
       "      <td>252.672455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>636.9317</td>\n",
       "      <td>10.62</td>\n",
       "      <td>1.325169</td>\n",
       "      <td>27</td>\n",
       "      <td>306.182312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>656.0490</td>\n",
       "      <td>10.93</td>\n",
       "      <td>1.362022</td>\n",
       "      <td>32</td>\n",
       "      <td>810.230347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>598.8393</td>\n",
       "      <td>9.98</td>\n",
       "      <td>1.167735</td>\n",
       "      <td>50</td>\n",
       "      <td>486.180145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name  max_length  emb_dim  attention_heads  layers  dropout  learning_rate   \n",
       "0   a1        1024      256                4       6        0          0.001  \\\n",
       "1   a2        1024      256                4       6        0          0.001   \n",
       "2   a3        1024      256                4       6        0          0.001   \n",
       "3    b        1024      256                4       6        0          0.001   \n",
       "4    c        1024      256                4       6        0          0.001   \n",
       "5    d        1024      256                4       6        0          0.001   \n",
       "\n",
       "   epochs  batch_size  ran   runtime  runtime_min  min_loss  at_epoch   \n",
       "0      50           4  yes  717.6662        11.96  1.373842        42  \\\n",
       "1      50           4  yes  716.0189        11.93  1.140858        49   \n",
       "2      50           4  yes  696.7114        11.61  1.342281        34   \n",
       "3      50           4  yes  636.9317        10.62  1.325169        27   \n",
       "4      50           4  yes  656.0490        10.93  1.362022        32   \n",
       "5      50           4  yes  598.8393         9.98  1.167735        50   \n",
       "\n",
       "   perplexity  incorrect_notes  correct_notes  correct_rate  \n",
       "0  423.106567              NaN            NaN           NaN  \n",
       "1  472.513916              NaN            NaN           NaN  \n",
       "2  252.672455              NaN            NaN           NaN  \n",
       "3  306.182312              NaN            NaN           NaN  \n",
       "4  810.230347              NaN            NaN           NaN  \n",
       "5  486.180145              NaN            NaN           NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = pd.read_excel(f\"{PATH_MODELS}/comparison_model_stats.xlsx\", index_col=\"Unnamed: 0\")\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5131b4e3-410f-45c2-8fd6-9694d140ea56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:211 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:214 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midi saved in ../0_data/8_predictions/midi/a1/generated_midi_0.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/a1/generated_midi_1.midi\n",
      "Number of incorrect notes: 1\n",
      "midi saved in ../0_data/8_predictions/midi/a1/generated_midi_2.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/a1/generated_midi_3.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/a1/generated_midi_4.midi\n",
      "Number of incorrect notes: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:179 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midi saved in ../0_data/8_predictions/midi/a2/generated_midi_0.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/a2/generated_midi_1.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/a2/generated_midi_2.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/a2/generated_midi_3.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/a2/generated_midi_4.midi\n",
      "Number of incorrect notes: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:211 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midi saved in ../0_data/8_predictions/midi/a3/generated_midi_0.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/a3/generated_midi_1.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/a3/generated_midi_2.midi\n",
      "Number of incorrect notes: 1\n",
      "midi saved in ../0_data/8_predictions/midi/a3/generated_midi_3.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/a3/generated_midi_4.midi\n",
      "Number of incorrect notes: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:119 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midi saved in ../0_data/8_predictions/midi/b/generated_midi_0.midi\n",
      "Number of incorrect notes: 1\n",
      "midi saved in ../0_data/8_predictions/midi/b/generated_midi_1.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/b/generated_midi_2.midi\n",
      "Number of incorrect notes: 1\n",
      "midi saved in ../0_data/8_predictions/midi/b/generated_midi_3.midi\n",
      "Number of incorrect notes: 4\n",
      "midi saved in ../0_data/8_predictions/midi/b/generated_midi_4.midi\n",
      "Number of incorrect notes: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:90 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "midi saved in ../0_data/8_predictions/midi/c/generated_midi_0.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/c/generated_midi_1.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/c/generated_midi_2.midi\n",
      "Number of incorrect notes: 1\n",
      "midi saved in ../0_data/8_predictions/midi/c/generated_midi_3.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/c/generated_midi_4.midi\n",
      "Number of incorrect notes: 1\n",
      "midi saved in ../0_data/8_predictions/midi/d/generated_midi_0.midi\n",
      "Number of incorrect notes: 1\n",
      "midi saved in ../0_data/8_predictions/midi/d/generated_midi_1.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/d/generated_midi_2.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/d/generated_midi_3.midi\n",
      "Number of incorrect notes: 0\n",
      "midi saved in ../0_data/8_predictions/midi/d/generated_midi_4.midi\n",
      "Number of incorrect notes: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>max_length</th>\n",
       "      <th>emb_dim</th>\n",
       "      <th>attention_heads</th>\n",
       "      <th>layers</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>ran</th>\n",
       "      <th>runtime</th>\n",
       "      <th>runtime_min</th>\n",
       "      <th>min_loss</th>\n",
       "      <th>at_epoch</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>incorrect_notes</th>\n",
       "      <th>correct_notes</th>\n",
       "      <th>correct_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>717.6662</td>\n",
       "      <td>11.96</td>\n",
       "      <td>1.373842</td>\n",
       "      <td>42</td>\n",
       "      <td>423.106567</td>\n",
       "      <td>0.2</td>\n",
       "      <td>323.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>716.0189</td>\n",
       "      <td>11.93</td>\n",
       "      <td>1.140858</td>\n",
       "      <td>49</td>\n",
       "      <td>472.513916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>308.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>696.7114</td>\n",
       "      <td>11.61</td>\n",
       "      <td>1.342281</td>\n",
       "      <td>34</td>\n",
       "      <td>252.672455</td>\n",
       "      <td>0.2</td>\n",
       "      <td>322.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>636.9317</td>\n",
       "      <td>10.62</td>\n",
       "      <td>1.325169</td>\n",
       "      <td>27</td>\n",
       "      <td>306.182312</td>\n",
       "      <td>1.2</td>\n",
       "      <td>324.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>656.0490</td>\n",
       "      <td>10.93</td>\n",
       "      <td>1.362022</td>\n",
       "      <td>32</td>\n",
       "      <td>810.230347</td>\n",
       "      <td>0.4</td>\n",
       "      <td>322.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>598.8393</td>\n",
       "      <td>9.98</td>\n",
       "      <td>1.167735</td>\n",
       "      <td>50</td>\n",
       "      <td>486.180145</td>\n",
       "      <td>0.2</td>\n",
       "      <td>253.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  name  max_length  emb_dim  attention_heads  layers  dropout  learning_rate   \n",
       "0   a1        1024      256                4       6        0          0.001  \\\n",
       "1   a2        1024      256                4       6        0          0.001   \n",
       "2   a3        1024      256                4       6        0          0.001   \n",
       "3    b        1024      256                4       6        0          0.001   \n",
       "4    c        1024      256                4       6        0          0.001   \n",
       "5    d        1024      256                4       6        0          0.001   \n",
       "\n",
       "   epochs  batch_size  ran   runtime  runtime_min  min_loss  at_epoch   \n",
       "0      50           4  yes  717.6662        11.96  1.373842        42  \\\n",
       "1      50           4  yes  716.0189        11.93  1.140858        49   \n",
       "2      50           4  yes  696.7114        11.61  1.342281        34   \n",
       "3      50           4  yes  636.9317        10.62  1.325169        27   \n",
       "4      50           4  yes  656.0490        10.93  1.362022        32   \n",
       "5      50           4  yes  598.8393         9.98  1.167735        50   \n",
       "\n",
       "   perplexity  incorrect_notes  correct_notes  correct_rate  \n",
       "0  423.106567              0.2          323.4           1.0  \n",
       "1  472.513916              0.0          308.8           1.0  \n",
       "2  252.672455              0.2          322.8           1.0  \n",
       "3  306.182312              1.2          324.4           1.0  \n",
       "4  810.230347              0.4          322.4           1.0  \n",
       "5  486.180145              0.2          253.0           1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TICKS_PER_BEAT = 1024\n",
    "TICKS_PER_MIN_DURATION = TICKS_PER_BEAT*4/32\n",
    "    \n",
    "for index, row in model_df.iterrows():\n",
    "\n",
    "    # only models that ran\n",
    "    if row[\"ran\"] == \"no\" or pd.notnull(row[\"incorrect_notes\"]) or row[\"runtime\"] == \"too big - cuda error\":\n",
    "        continue\n",
    "    \n",
    "    model_name = row[\"name\"]\n",
    "    if not os.path.exists(f\"{PATH_MIDI}/{model_name}\"):\n",
    "        os.makedirs(f\"{PATH_MIDI}/{model_name}\")\n",
    "\n",
    "    # get token flags and duration bins\n",
    "    token_flags = get_token_flags(vocab_configs[model_name])\n",
    "    duration_steps = vocab_configs[model_name][\"duration_steps\"]\n",
    "    duration_bins = np.arange(TICKS_PER_MIN_DURATION, (TICKS_PER_MIN_DURATION*duration_steps)+1, TICKS_PER_MIN_DURATION, dtype=int)\n",
    "\n",
    "    # create tokenizer\n",
    "    tokenizer = GPT2Tokenizer(\n",
    "        vocab_file=f\"{PATH_VOCAB}/vocab_{model_name}.json\", \n",
    "        merges_file=f\"{PATH_VOCAB}/merges.txt\")\n",
    "    tokenizer.add_special_tokens({'pad_token': 'PAD', 'bos_token': 'BOS', 'eos_token': 'EOS',})\n",
    "    \n",
    "    # get vocabulary\n",
    "    with open(f\"{PATH_VOCAB}/vocab_{model_name}.json\", \"r\") as fp:\n",
    "        vocab = json.load(fp)\n",
    "    token2word = {token: word for word, token in vocab.items()}\n",
    "\n",
    "    # load model\n",
    "    model = GPT2LMHeadModel.from_pretrained(f\"{PATH_MODELS_CONFIG}/{model_name}/end_version\")\n",
    "    \n",
    "    # make predictions save\n",
    "    output = predict(model, tokenizer, samples=5, max_length=row[\"max_length\"])\n",
    "    data_generated = {\"data\": output}\n",
    "    \n",
    "    with open(f\"{PATH_TOKENS}/{model_name}.json\", \"w\") as fp:\n",
    "        json.dump(data_generated, fp)\n",
    "    \n",
    "    # analyze tokens and save as midi_files\n",
    "    correct_notes = 0\n",
    "    incorrect_notes = 0\n",
    "    for idx, pred in enumerate(output):\n",
    "        an = analyze_token_sequence(pred, token_flags)\n",
    "        correct_notes += an[\"start-pos-pitch-duration\"] + an[\"start-pos-pitch-duration-dtriole\"] + an[\"start-pos-ptriole-pitch-duration\"] + an[\"start-pos-ptriole-pitch-duration-dtriole\"]\n",
    "        incorrect_notes += write_midi(output[idx], token2word, duration_bins, f\"{PATH_MIDI}/{model_name}/generated_midi_{idx}.midi\")\n",
    "    \n",
    "    model_df.at[index,\"correct_notes\"] = (correct_notes/5).__round__(2)\n",
    "    model_df.at[index,\"incorrect_notes\"] = (incorrect_notes/5).__round__(2)\n",
    "    model_df.at[index,\"correct_rate\"] = (correct_notes/(correct_notes+incorrect_notes)).__round__(2)\n",
    "    \n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b740e33-4072-4e3c-b3f0-7f471aaf645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.to_excel(f\"{PATH_MODELS}/comparison_model_stats.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416e543-751c-4d86-98cc-4697915c5669",
   "metadata": {},
   "source": [
    "run \"tar chvfz predictions_midi.tar.gz *\" in terminal midi folder to create and download zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cc98a-ac66-439f-9995-53bedde78d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2469cc5-a929-4fab-97e3-10a9acee4c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f93517dc-e5aa-409e-b220-31b16da1655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Andere Variante ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2e116b1-25ee-40f1-8930-1aac99878b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 120])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(inputs)\n",
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86de9d10-35b3-4286-9e42-264c9696e409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1162, -2.1350, -3.5313, -1.9780, -3.5414, -1.5776, -1.8704,\n",
       "          -3.5441, -1.1535, -2.6672, -0.8764, -2.2812, -1.6335, -0.8708,\n",
       "          -2.7905, -1.4720, -2.4843, -0.5825, -2.0775, -2.7744, -1.5724,\n",
       "          -3.7235, -1.8095, -2.4802, -2.3428, -2.3748, -3.2765, -2.9800,\n",
       "          -3.1671, -2.6769, -3.6342, -3.3965, -2.9433, -3.3021, -3.6102,\n",
       "          -3.8760, -3.8078, -2.8941, -0.2965, -3.4592, -0.6409, -3.7882,\n",
       "          -1.4499, -3.6240, -0.8940, -3.3144, -1.9948, -3.0505, -2.1582,\n",
       "          -3.2950, -2.2917, -3.4952, -1.5516, -3.7166, -2.3756, -3.3413,\n",
       "          -2.5331, -3.7758, -2.4212, -3.4614, -2.8825, -3.7335, -2.9825,\n",
       "          -2.8619, -2.9172, -3.3198, -3.0439, -2.9400, -1.7772, -3.4107,\n",
       "          -3.0528, -3.1332, -3.2200, -3.2291, -2.9769, -3.1939, -1.9817,\n",
       "          -2.9937, -2.8389, -3.1996, -2.9903, -2.9885, -3.7754, -3.6936,\n",
       "          -3.1062, -3.3149, -3.9010, -3.4983, -3.7158, -3.4427, -3.5639,\n",
       "          -3.5325, -1.8639, -3.7709, -3.4870, -3.2223, -3.6571, -3.4250,\n",
       "          -3.6030, -3.3400, -2.2445,  0.1584,  3.4136,  4.2250,  4.2018,\n",
       "           3.7291,  3.9138,  4.1381,  4.0495,  3.2906,  3.4570,  3.8709,\n",
       "           3.7553,  3.1699,  3.3294,  3.8238,  3.7216,  3.2188, -0.7025,\n",
       "          -0.8708]]], device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76458b6d-c49b-4599-9721-25aece094438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temperature value\n",
    "temperature = 13\n",
    "\n",
    "# Convert logits to probabilities using softmax with temperature\n",
    "probs = F.softmax(outputs.logits / temperature, dim=-1)\n",
    "\n",
    "# Sample a token from the probability distribution for each position in the sequence\n",
    "predicted_tokens = torch.multinomial(probs.view(-1, probs.shape[-1]), num_samples=1).view(*probs.shape[:-1])\n",
    "predicted_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fa664ea-d774-4f8b-9367-f3f5ea2efc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Note-On_83'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(predicted_tokens[0], skip_special_tokens=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [pipenv: PyEnv]",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
