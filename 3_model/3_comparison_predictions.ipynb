{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f97d2f-6ac1-4348-8876-690002b854db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_functions import analyze_token_sequence, predict, write_midi, get_token_flags\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Config, GPT2Tokenizer, GPT2LMHeadModel, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    "\n",
    "PATH_VOCAB = \"../0_data/5_vocabs\"\n",
    "PATH_MODELS = \"../0_data/7_models\"\n",
    "PATH_MODELS_CONFIG = \"../0_data/7_models/config\"\n",
    "PATH_PRED = \"../0_data/8_predictions\"\n",
    "PATH_TOKENS = \"../0_data/8_predictions/tokens\"\n",
    "PATH_MIDI = \"../0_data/8_predictions/midi\"\n",
    "\n",
    "for path in [PATH_PRED, PATH_TOKENS, PATH_MIDI]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbfd68e1-0b3f-480c-91df-5934fa5e91b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_configs = {\n",
    "    \"a1\" : {\n",
    "        \"pitch_range\": 128,\n",
    "        \"duration_steps\": 64,\n",
    "        \"triole_tokens\": False,\n",
    "    },\n",
    "    \"a2\" : {\n",
    "        \"pitch_range\": 128,\n",
    "        \"duration_steps\": 64,\n",
    "        \"triole_tokens\": True,\n",
    "    },\n",
    "    \"a3\" : {\n",
    "        \"pitch_range\": 128,\n",
    "        \"duration_steps\": 32,\n",
    "        \"triole_tokens\": False,\n",
    "    },\n",
    "    \"b\" : {\n",
    "        \"pitch_range\": 128,\n",
    "        \"duration_steps\": 64,\n",
    "        \"triole_tokens\": False,\n",
    "    },\n",
    "    \"c\" : {\n",
    "        \"pitch_range\": 36,\n",
    "        \"duration_steps\": 64,\n",
    "        \"triole_tokens\": False,\n",
    "    },\n",
    "    \"d\" : {\n",
    "        \"pitch_range\": 36,\n",
    "        \"duration_steps\": 32,\n",
    "        \"triole_tokens\": True,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1befc7-5ced-4b36-b13d-b1bb9778d663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>max_length</th>\n",
       "      <th>emb_dim</th>\n",
       "      <th>attention_heads</th>\n",
       "      <th>layers</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>ran</th>\n",
       "      <th>runtime</th>\n",
       "      <th>runtime_min</th>\n",
       "      <th>min_loss</th>\n",
       "      <th>at_epoch</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>incorrect_notes</th>\n",
       "      <th>correct_notes</th>\n",
       "      <th>correct_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>633.0726</td>\n",
       "      <td>10.55</td>\n",
       "      <td>1.341614</td>\n",
       "      <td>33</td>\n",
       "      <td>400.472565</td>\n",
       "      <td>0.21</td>\n",
       "      <td>321.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>660.1042</td>\n",
       "      <td>11.00</td>\n",
       "      <td>1.133472</td>\n",
       "      <td>41</td>\n",
       "      <td>206.331863</td>\n",
       "      <td>0.25</td>\n",
       "      <td>285.16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>636.4971</td>\n",
       "      <td>10.61</td>\n",
       "      <td>1.348449</td>\n",
       "      <td>36</td>\n",
       "      <td>167.751266</td>\n",
       "      <td>0.25</td>\n",
       "      <td>319.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>636.4864</td>\n",
       "      <td>10.61</td>\n",
       "      <td>1.349513</td>\n",
       "      <td>36</td>\n",
       "      <td>254.352493</td>\n",
       "      <td>0.40</td>\n",
       "      <td>321.09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>669.2868</td>\n",
       "      <td>11.15</td>\n",
       "      <td>1.340456</td>\n",
       "      <td>36</td>\n",
       "      <td>163.397003</td>\n",
       "      <td>0.28</td>\n",
       "      <td>320.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>655.0100</td>\n",
       "      <td>10.92</td>\n",
       "      <td>1.167735</td>\n",
       "      <td>50</td>\n",
       "      <td>486.180145</td>\n",
       "      <td>0.34</td>\n",
       "      <td>278.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>265.2580</td>\n",
       "      <td>4.42</td>\n",
       "      <td>1.345365</td>\n",
       "      <td>20</td>\n",
       "      <td>137.914551</td>\n",
       "      <td>0.45</td>\n",
       "      <td>321.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a2</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>260.7209</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1.202786</td>\n",
       "      <td>20</td>\n",
       "      <td>120.460831</td>\n",
       "      <td>0.24</td>\n",
       "      <td>280.73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a3</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>262.6342</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.377196</td>\n",
       "      <td>20</td>\n",
       "      <td>177.487762</td>\n",
       "      <td>0.35</td>\n",
       "      <td>321.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>265.6575</td>\n",
       "      <td>4.43</td>\n",
       "      <td>1.343577</td>\n",
       "      <td>20</td>\n",
       "      <td>188.348267</td>\n",
       "      <td>0.27</td>\n",
       "      <td>322.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>267.9921</td>\n",
       "      <td>4.47</td>\n",
       "      <td>1.347643</td>\n",
       "      <td>20</td>\n",
       "      <td>138.114548</td>\n",
       "      <td>0.26</td>\n",
       "      <td>321.44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>d</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>255.7635</td>\n",
       "      <td>4.26</td>\n",
       "      <td>1.210535</td>\n",
       "      <td>20</td>\n",
       "      <td>399.204498</td>\n",
       "      <td>0.33</td>\n",
       "      <td>285.27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  max_length  emb_dim  attention_heads  layers  dropout   \n",
       "0   a1_50        1024      256                4       6        0  \\\n",
       "1   a2_50        1024      256                4       6        0   \n",
       "2   a3_50        1024      256                4       6        0   \n",
       "3    b_50        1024      256                4       6        0   \n",
       "4    c_50        1024      256                4       6        0   \n",
       "5    d_50        1024      256                4       6        0   \n",
       "6      a1        1024      256                4       6        0   \n",
       "7      a2        1024      256                4       6        0   \n",
       "8      a3        1024      256                4       6        0   \n",
       "9       b        1024      256                4       6        0   \n",
       "10      c        1024      256                4       6        0   \n",
       "11      d        1024      256                4       6        0   \n",
       "\n",
       "    learning_rate  epochs  batch_size  ran   runtime  runtime_min  min_loss   \n",
       "0           0.001      50           4  yes  633.0726        10.55  1.341614  \\\n",
       "1           0.001      50           4  yes  660.1042        11.00  1.133472   \n",
       "2           0.001      50           4  yes  636.4971        10.61  1.348449   \n",
       "3           0.001      50           4  yes  636.4864        10.61  1.349513   \n",
       "4           0.001      50           4  yes  669.2868        11.15  1.340456   \n",
       "5           0.001      50           4  yes  655.0100        10.92  1.167735   \n",
       "6           0.001      20           4  yes  265.2580         4.42  1.345365   \n",
       "7           0.001      20           4  yes  260.7209         4.35  1.202786   \n",
       "8           0.001      20           4  yes  262.6342         4.38  1.377196   \n",
       "9           0.001      20           4  yes  265.6575         4.43  1.343577   \n",
       "10          0.001      20           4  yes  267.9921         4.47  1.347643   \n",
       "11          0.001      20           4  yes  255.7635         4.26  1.210535   \n",
       "\n",
       "    at_epoch  perplexity  incorrect_notes  correct_notes  correct_rate  \n",
       "0         33  400.472565             0.21         321.04             1  \n",
       "1         41  206.331863             0.25         285.16             1  \n",
       "2         36  167.751266             0.25         319.93             1  \n",
       "3         36  254.352493             0.40         321.09             1  \n",
       "4         36  163.397003             0.28         320.76             1  \n",
       "5         50  486.180145             0.34         278.31             1  \n",
       "6         20  137.914551             0.45         321.32             1  \n",
       "7         20  120.460831             0.24         280.73             1  \n",
       "8         20  177.487762             0.35         321.58             1  \n",
       "9         20  188.348267             0.27         322.53             1  \n",
       "10        20  138.114548             0.26         321.44             1  \n",
       "11        20  399.204498             0.33         285.27             1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = pd.read_excel(f\"{PATH_MODELS}/comparison_model_stats.xlsx\", index_col=\"Unnamed: 0\")\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5131b4e3-410f-45c2-8fd6-9694d140ea56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>max_length</th>\n",
       "      <th>emb_dim</th>\n",
       "      <th>attention_heads</th>\n",
       "      <th>layers</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>ran</th>\n",
       "      <th>runtime</th>\n",
       "      <th>runtime_min</th>\n",
       "      <th>min_loss</th>\n",
       "      <th>at_epoch</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>incorrect_notes</th>\n",
       "      <th>correct_notes</th>\n",
       "      <th>correct_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>633.0726</td>\n",
       "      <td>10.55</td>\n",
       "      <td>1.341614</td>\n",
       "      <td>33</td>\n",
       "      <td>400.472565</td>\n",
       "      <td>0.21</td>\n",
       "      <td>321.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a2_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>660.1042</td>\n",
       "      <td>11.00</td>\n",
       "      <td>1.133472</td>\n",
       "      <td>41</td>\n",
       "      <td>206.331863</td>\n",
       "      <td>0.25</td>\n",
       "      <td>285.16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a3_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>636.4971</td>\n",
       "      <td>10.61</td>\n",
       "      <td>1.348449</td>\n",
       "      <td>36</td>\n",
       "      <td>167.751266</td>\n",
       "      <td>0.25</td>\n",
       "      <td>319.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>636.4864</td>\n",
       "      <td>10.61</td>\n",
       "      <td>1.349513</td>\n",
       "      <td>36</td>\n",
       "      <td>254.352493</td>\n",
       "      <td>0.40</td>\n",
       "      <td>321.09</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>669.2868</td>\n",
       "      <td>11.15</td>\n",
       "      <td>1.340456</td>\n",
       "      <td>36</td>\n",
       "      <td>163.397003</td>\n",
       "      <td>0.28</td>\n",
       "      <td>320.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>d_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>655.0100</td>\n",
       "      <td>10.92</td>\n",
       "      <td>1.167735</td>\n",
       "      <td>50</td>\n",
       "      <td>486.180145</td>\n",
       "      <td>0.34</td>\n",
       "      <td>278.31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a1</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>265.2580</td>\n",
       "      <td>4.42</td>\n",
       "      <td>1.345365</td>\n",
       "      <td>20</td>\n",
       "      <td>137.914551</td>\n",
       "      <td>0.45</td>\n",
       "      <td>321.32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a2</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>260.7209</td>\n",
       "      <td>4.35</td>\n",
       "      <td>1.202786</td>\n",
       "      <td>20</td>\n",
       "      <td>120.460831</td>\n",
       "      <td>0.24</td>\n",
       "      <td>280.73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a3</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>262.6342</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.377196</td>\n",
       "      <td>20</td>\n",
       "      <td>177.487762</td>\n",
       "      <td>0.35</td>\n",
       "      <td>321.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>265.6575</td>\n",
       "      <td>4.43</td>\n",
       "      <td>1.343577</td>\n",
       "      <td>20</td>\n",
       "      <td>188.348267</td>\n",
       "      <td>0.27</td>\n",
       "      <td>322.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>c</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>267.9921</td>\n",
       "      <td>4.47</td>\n",
       "      <td>1.347643</td>\n",
       "      <td>20</td>\n",
       "      <td>138.114548</td>\n",
       "      <td>0.26</td>\n",
       "      <td>321.44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>d</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>255.7635</td>\n",
       "      <td>4.26</td>\n",
       "      <td>1.210535</td>\n",
       "      <td>20</td>\n",
       "      <td>399.204498</td>\n",
       "      <td>0.33</td>\n",
       "      <td>285.27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  max_length  emb_dim  attention_heads  layers  dropout   \n",
       "0   a1_50        1024      256                4       6        0  \\\n",
       "1   a2_50        1024      256                4       6        0   \n",
       "2   a3_50        1024      256                4       6        0   \n",
       "3    b_50        1024      256                4       6        0   \n",
       "4    c_50        1024      256                4       6        0   \n",
       "5    d_50        1024      256                4       6        0   \n",
       "6      a1        1024      256                4       6        0   \n",
       "7      a2        1024      256                4       6        0   \n",
       "8      a3        1024      256                4       6        0   \n",
       "9       b        1024      256                4       6        0   \n",
       "10      c        1024      256                4       6        0   \n",
       "11      d        1024      256                4       6        0   \n",
       "\n",
       "    learning_rate  epochs  batch_size  ran   runtime  runtime_min  min_loss   \n",
       "0           0.001      50           4  yes  633.0726        10.55  1.341614  \\\n",
       "1           0.001      50           4  yes  660.1042        11.00  1.133472   \n",
       "2           0.001      50           4  yes  636.4971        10.61  1.348449   \n",
       "3           0.001      50           4  yes  636.4864        10.61  1.349513   \n",
       "4           0.001      50           4  yes  669.2868        11.15  1.340456   \n",
       "5           0.001      50           4  yes  655.0100        10.92  1.167735   \n",
       "6           0.001      20           4  yes  265.2580         4.42  1.345365   \n",
       "7           0.001      20           4  yes  260.7209         4.35  1.202786   \n",
       "8           0.001      20           4  yes  262.6342         4.38  1.377196   \n",
       "9           0.001      20           4  yes  265.6575         4.43  1.343577   \n",
       "10          0.001      20           4  yes  267.9921         4.47  1.347643   \n",
       "11          0.001      20           4  yes  255.7635         4.26  1.210535   \n",
       "\n",
       "    at_epoch  perplexity  incorrect_notes  correct_notes  correct_rate  \n",
       "0         33  400.472565             0.21         321.04             1  \n",
       "1         41  206.331863             0.25         285.16             1  \n",
       "2         36  167.751266             0.25         319.93             1  \n",
       "3         36  254.352493             0.40         321.09             1  \n",
       "4         36  163.397003             0.28         320.76             1  \n",
       "5         50  486.180145             0.34         278.31             1  \n",
       "6         20  137.914551             0.45         321.32             1  \n",
       "7         20  120.460831             0.24         280.73             1  \n",
       "8         20  177.487762             0.35         321.58             1  \n",
       "9         20  188.348267             0.27         322.53             1  \n",
       "10        20  138.114548             0.26         321.44             1  \n",
       "11        20  399.204498             0.33         285.27             1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TICKS_PER_BEAT = 1024\n",
    "TICKS_PER_MIN_DURATION = TICKS_PER_BEAT*4/32\n",
    "    \n",
    "for index, row in model_df.iterrows():\n",
    "\n",
    "    # only models that ran\n",
    "    if row[\"ran\"] == \"no\" or pd.notnull(row[\"incorrect_notes\"]) or row[\"runtime\"] == \"too big - cuda error\":\n",
    "        continue\n",
    "    \n",
    "    model_name = row[\"name\"]\n",
    "    model_vocab = model_name.split(\"_\")[0]\n",
    "    \n",
    "    if not os.path.exists(f\"{PATH_MIDI}/{model_name}\"):\n",
    "        os.makedirs(f\"{PATH_MIDI}/{model_name}\")\n",
    "\n",
    "    # get token flags and duration bins\n",
    "    token_flags = get_token_flags(vocab_configs[model_vocab])\n",
    "    duration_steps = vocab_configs[model_vocab][\"duration_steps\"]\n",
    "    duration_bins = np.arange(TICKS_PER_MIN_DURATION, (TICKS_PER_MIN_DURATION*duration_steps)+1, TICKS_PER_MIN_DURATION, dtype=int)\n",
    "\n",
    "    # create tokenizer\n",
    "    tokenizer = GPT2Tokenizer(\n",
    "        vocab_file=f\"{PATH_VOCAB}/vocab_{model_vocab}.json\", \n",
    "        merges_file=f\"{PATH_VOCAB}/merges.txt\")\n",
    "    tokenizer.add_special_tokens({'pad_token': 'PAD', 'bos_token': 'BOS', 'eos_token': 'EOS',})\n",
    "    \n",
    "    # get vocabulary\n",
    "    with open(f\"{PATH_VOCAB}/vocab_{model_vocab}.json\", \"r\") as fp:\n",
    "        vocab = json.load(fp)\n",
    "    token2word = {token: word for word, token in vocab.items()}\n",
    "\n",
    "    # load model\n",
    "    model = GPT2LMHeadModel.from_pretrained(f\"{PATH_MODELS_CONFIG}/{model_name}/end_version\")\n",
    "    \n",
    "    # make predictions save\n",
    "    output = predict(model, tokenizer, samples=100, max_length=row[\"max_length\"])\n",
    "    data_generated = {\"data\": output}\n",
    "    \n",
    "    with open(f\"{PATH_TOKENS}/{model_name}.json\", \"w\") as fp:\n",
    "        json.dump(data_generated, fp)\n",
    "    \n",
    "    # analyze tokens and save as midi_files\n",
    "    correct_notes = 0\n",
    "    incorrect_notes = 0\n",
    "    for idx, pred in enumerate(output):\n",
    "        an = analyze_token_sequence(pred, token_flags)\n",
    "        correct_notes += an[\"start-pos-pitch-duration\"] + an[\"start-pos-pitch-duration-dtriole\"] + an[\"start-pos-ptriole-pitch-duration\"] + an[\"start-pos-ptriole-pitch-duration-dtriole\"]\n",
    "        incorrect_notes += write_midi(output[idx], token2word, duration_bins, f\"{PATH_MIDI}/{model_name}/generated_midi_{idx}.midi\")\n",
    "    \n",
    "    model_df.at[index,\"correct_notes\"] = (correct_notes/100).__round__(2)\n",
    "    model_df.at[index,\"incorrect_notes\"] = (incorrect_notes/100).__round__(2)\n",
    "    model_df.at[index,\"correct_rate\"] = (correct_notes/(correct_notes+incorrect_notes)).__round__(2)\n",
    "    \n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b740e33-4072-4e3c-b3f0-7f471aaf645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.to_excel(f\"{PATH_MODELS}/comparison_model_stats.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416e543-751c-4d86-98cc-4697915c5669",
   "metadata": {},
   "source": [
    "run \"tar chvfz predictions_midi.tar.gz *\" in terminal midi folder to create and download zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [pipenv: PyEnv]",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
