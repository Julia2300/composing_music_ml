{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4f97d2f-6ac1-4348-8876-690002b854db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_functions import analyze_token_sequence, predict, write_midi\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from transformers import GPT2Config, GPT2Tokenizer, GPT2LMHeadModel, DataCollatorForLanguageModeling, TrainingArguments, Trainer\n",
    "\n",
    "PATH_VOCAB = \"../0_data/5_vocabs\"\n",
    "PATH_MODELS = \"../0_data/7_models\"\n",
    "PATH_MODELS_CONFIG = \"../0_data/7_models/config\"\n",
    "PATH_PRED = \"../0_data/8_predictions\"\n",
    "PATH_TOKENS = \"../0_data/8_predictions/tokens\"\n",
    "PATH_MIDI = \"../0_data/8_predictions/midi\"\n",
    "\n",
    "for path in [PATH_PRED, PATH_TOKENS, PATH_MIDI]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1521cdc-0c06-404a-96f8-42b9555a6047",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tokeinzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0965cee9-aa71-4575-bf8f-caf7a7966c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer(\n",
    "    vocab_file=f\"{PATH_VOCAB}/vocab_d.json\", \n",
    "    merges_file=f\"{PATH_VOCAB}/merges.txt\")\n",
    "tokenizer.add_special_tokens({'pad_token': 'PAD', 'bos_token': 'BOS', 'eos_token': 'EOS',})\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba1ba90-ec3e-472a-b856-598ba8714138",
   "metadata": {},
   "source": [
    "## Get Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4209c11-6425-46ed-aa35-117b740bf49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{PATH_VOCAB}/vocab_d.json\", \"r\") as fp:\n",
    "    vocab = json.load(fp)\n",
    "token2word = {token: word for word, token in vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf250d04-6959-453a-b327-c63ae5a81bb2",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb90600e-8050-4168-b5c8-bda931aeaa70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>max_length</th>\n",
       "      <th>emb_dim</th>\n",
       "      <th>attention_heads</th>\n",
       "      <th>layers</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>ran</th>\n",
       "      <th>runtime</th>\n",
       "      <th>runtime_min</th>\n",
       "      <th>min_loss</th>\n",
       "      <th>at_epoch</th>\n",
       "      <th>incorrect_notes</th>\n",
       "      <th>correct_notes</th>\n",
       "      <th>correct_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_short_small_50</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>185.6872</td>\n",
       "      <td>3.09</td>\n",
       "      <td>1.163706</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.8</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_short_medium_50</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>286.7629</td>\n",
       "      <td>4.78</td>\n",
       "      <td>1.251897</td>\n",
       "      <td>24</td>\n",
       "      <td>0.2</td>\n",
       "      <td>70.4</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_short_large_50</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>568.0452</td>\n",
       "      <td>9.47</td>\n",
       "      <td>1.973589</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.6</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4_middle_small_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>248.7667</td>\n",
       "      <td>4.15</td>\n",
       "      <td>1.087204</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.8</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5_middle_medium_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>628.1603</td>\n",
       "      <td>10.47</td>\n",
       "      <td>1.120312</td>\n",
       "      <td>40</td>\n",
       "      <td>0.2</td>\n",
       "      <td>265.6</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6_middle_large_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>2247.7578</td>\n",
       "      <td>37.46</td>\n",
       "      <td>1.872430</td>\n",
       "      <td>48</td>\n",
       "      <td>0.4</td>\n",
       "      <td>289.8</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7_long_small_50</td>\n",
       "      <td>2048</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>491.8461</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1.202734</td>\n",
       "      <td>50</td>\n",
       "      <td>1.6</td>\n",
       "      <td>546.8</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8_long_medium_50</td>\n",
       "      <td>2048</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>1506.3536</td>\n",
       "      <td>25.11</td>\n",
       "      <td>1.154148</td>\n",
       "      <td>37</td>\n",
       "      <td>2.8</td>\n",
       "      <td>526.8</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9_long_large_50</td>\n",
       "      <td>2048</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>5933.9392</td>\n",
       "      <td>98.90</td>\n",
       "      <td>1.284094</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>552.2</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  max_length  emb_dim  attention_heads  layers  dropout   \n",
       "0    1_short_small_50         256      128                2       3     0.01  \\\n",
       "1   2_short_medium_50         256      256                4       6     0.01   \n",
       "2    3_short_large_50         256      512                8      12     0.01   \n",
       "3   4_middle_small_50        1024      128                2       3     0.01   \n",
       "4  5_middle_medium_50        1024      256                4       6     0.01   \n",
       "5   6_middle_large_50        1024      512                8      12     0.01   \n",
       "6     7_long_small_50        2048      128                2       3     0.01   \n",
       "7    8_long_medium_50        2048      256                4       6     0.01   \n",
       "8     9_long_large_50        2048      512                8      12     0.01   \n",
       "\n",
       "   learning_rate  epochs  batch_size  ran    runtime  runtime_min  min_loss   \n",
       "0          0.001      50           4  yes   185.6872         3.09  1.163706  \\\n",
       "1          0.001      50           4  yes   286.7629         4.78  1.251897   \n",
       "2          0.001      50           4  yes   568.0452         9.47  1.973589   \n",
       "3          0.001      50           4  yes   248.7667         4.15  1.087204   \n",
       "4          0.001      50           4  yes   628.1603        10.47  1.120312   \n",
       "5          0.001      50           4  yes  2247.7578        37.46  1.872430   \n",
       "6          0.001      50           4  yes   491.8461         8.20  1.202734   \n",
       "7          0.001      50           4  yes  1506.3536        25.11  1.154148   \n",
       "8          0.001      50           4  yes  5933.9392        98.90  1.284094   \n",
       "\n",
       "   at_epoch  incorrect_notes  correct_notes  correct_rate  \n",
       "0        50              0.0           65.8          1.00  \n",
       "1        24              0.2           70.4          1.00  \n",
       "2        50              0.0           74.6          1.00  \n",
       "3        50              0.0          264.8          1.00  \n",
       "4        40              0.2          265.6          1.00  \n",
       "5        48              0.4          289.8          1.00  \n",
       "6        50              1.6          546.8          1.00  \n",
       "7        37              2.8          526.8          0.99  \n",
       "8        50              0.2          552.2          1.00  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df = pd.read_excel(f\"{PATH_MODELS}/model_stats.xlsx\", index_col=\"Unnamed: 0\")\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcab6492-d322-4a05-91e9-ee4057d620c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>max_length</th>\n",
       "      <th>emb_dim</th>\n",
       "      <th>attention_heads</th>\n",
       "      <th>layers</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>ran</th>\n",
       "      <th>runtime</th>\n",
       "      <th>runtime_min</th>\n",
       "      <th>min_loss</th>\n",
       "      <th>at_epoch</th>\n",
       "      <th>incorrect_notes</th>\n",
       "      <th>correct_notes</th>\n",
       "      <th>correct_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_short_small_50</td>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>185.6872</td>\n",
       "      <td>3.09</td>\n",
       "      <td>1.163706</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.8</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2_short_medium_50</td>\n",
       "      <td>256</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>286.7629</td>\n",
       "      <td>4.78</td>\n",
       "      <td>1.251897</td>\n",
       "      <td>24</td>\n",
       "      <td>0.2</td>\n",
       "      <td>70.4</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3_short_large_50</td>\n",
       "      <td>256</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>568.0452</td>\n",
       "      <td>9.47</td>\n",
       "      <td>1.973589</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.6</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4_middle_small_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>248.7667</td>\n",
       "      <td>4.15</td>\n",
       "      <td>1.087204</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.8</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5_middle_medium_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>628.1603</td>\n",
       "      <td>10.47</td>\n",
       "      <td>1.120312</td>\n",
       "      <td>40</td>\n",
       "      <td>0.2</td>\n",
       "      <td>265.6</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6_middle_large_50</td>\n",
       "      <td>1024</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>2247.7578</td>\n",
       "      <td>37.46</td>\n",
       "      <td>1.872430</td>\n",
       "      <td>48</td>\n",
       "      <td>0.4</td>\n",
       "      <td>289.8</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7_long_small_50</td>\n",
       "      <td>2048</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>491.8461</td>\n",
       "      <td>8.20</td>\n",
       "      <td>1.202734</td>\n",
       "      <td>50</td>\n",
       "      <td>1.6</td>\n",
       "      <td>546.8</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8_long_medium_50</td>\n",
       "      <td>2048</td>\n",
       "      <td>256</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>1506.3536</td>\n",
       "      <td>25.11</td>\n",
       "      <td>1.154148</td>\n",
       "      <td>37</td>\n",
       "      <td>2.8</td>\n",
       "      <td>526.8</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9_long_large_50</td>\n",
       "      <td>2048</td>\n",
       "      <td>512</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>50</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>5933.9392</td>\n",
       "      <td>98.90</td>\n",
       "      <td>1.284094</td>\n",
       "      <td>50</td>\n",
       "      <td>0.2</td>\n",
       "      <td>552.2</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  max_length  emb_dim  attention_heads  layers  dropout   \n",
       "0    1_short_small_50         256      128                2       3     0.01  \\\n",
       "1   2_short_medium_50         256      256                4       6     0.01   \n",
       "2    3_short_large_50         256      512                8      12     0.01   \n",
       "3   4_middle_small_50        1024      128                2       3     0.01   \n",
       "4  5_middle_medium_50        1024      256                4       6     0.01   \n",
       "5   6_middle_large_50        1024      512                8      12     0.01   \n",
       "6     7_long_small_50        2048      128                2       3     0.01   \n",
       "7    8_long_medium_50        2048      256                4       6     0.01   \n",
       "8     9_long_large_50        2048      512                8      12     0.01   \n",
       "\n",
       "   learning_rate  epochs  batch_size  ran    runtime  runtime_min  min_loss   \n",
       "0          0.001      50           4  yes   185.6872         3.09  1.163706  \\\n",
       "1          0.001      50           4  yes   286.7629         4.78  1.251897   \n",
       "2          0.001      50           4  yes   568.0452         9.47  1.973589   \n",
       "3          0.001      50           4  yes   248.7667         4.15  1.087204   \n",
       "4          0.001      50           4  yes   628.1603        10.47  1.120312   \n",
       "5          0.001      50           4  yes  2247.7578        37.46  1.872430   \n",
       "6          0.001      50           4  yes   491.8461         8.20  1.202734   \n",
       "7          0.001      50           4  yes  1506.3536        25.11  1.154148   \n",
       "8          0.001      50           4  yes  5933.9392        98.90  1.284094   \n",
       "\n",
       "   at_epoch  incorrect_notes  correct_notes  correct_rate  \n",
       "0        50              0.0           65.8          1.00  \n",
       "1        24              0.2           70.4          1.00  \n",
       "2        50              0.0           74.6          1.00  \n",
       "3        50              0.0          264.8          1.00  \n",
       "4        40              0.2          265.6          1.00  \n",
       "5        48              0.4          289.8          1.00  \n",
       "6        50              1.6          546.8          1.00  \n",
       "7        37              2.8          526.8          0.99  \n",
       "8        50              0.2          552.2          1.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TICKS_PER_BEAT = 1024\n",
    "TICKS_PER_MIN_DURATION = TICKS_PER_BEAT*4/32\n",
    "    \n",
    "for index, row in model_df.iterrows():\n",
    "\n",
    "    # only models that ran\n",
    "    if row[\"ran\"] == \"no\" or pd.notnull(row[\"incorrect_notes\"]) or row[\"runtime\"] == \"too big - cuda error\":\n",
    "        continue\n",
    "    \n",
    "    model_name = row[\"name\"]\n",
    "    \n",
    "    token_flags = {\n",
    "        \"start_pitch_token\": 1,\n",
    "        \"end_pitch_token\": 36,\n",
    "        \"start_duration_token\": 37,\n",
    "        \"end_duration_token\": 68,\n",
    "        \"duration_triole\": 69,\n",
    "        \"start_position_token\": 70,\n",
    "        \"end_position_token\": 85,\n",
    "        \"position_triole_1\": 86,\n",
    "        \"position_triole_2\": 87,\n",
    "    }\n",
    "    \n",
    "    duration_steps = 64    \n",
    "    duration_bins = np.arange(TICKS_PER_MIN_DURATION, (TICKS_PER_MIN_DURATION*duration_steps)+1, TICKS_PER_MIN_DURATION, dtype=int)\n",
    "\n",
    "    if not os.path.exists(f\"{PATH_MIDI}/{model_name}\"):\n",
    "        os.makedirs(f\"{PATH_MIDI}/{model_name}\")\n",
    "    \n",
    "    # load model\n",
    "    model = GPT2LMHeadModel.from_pretrained(f\"{PATH_MODELS_CONFIG}/{model_name}/end_version\")\n",
    "    \n",
    "    # make predictions save\n",
    "    output = predict(model, tokenizer, samples=5, max_length=row[\"max_length\"])\n",
    "    data_generated = {\"data\": output}\n",
    "    \n",
    "    with open(f\"{PATH_TOKENS}/{model_name}.json\", \"w\") as fp:\n",
    "        json.dump(data_generated, fp)\n",
    "    \n",
    "    # analyze tokens and save as midi_files\n",
    "    correct_notes = 0\n",
    "    incorrect_notes = 0\n",
    "    for idx, pred in enumerate(output):\n",
    "        an = analyze_token_sequence(pred, token_flags)\n",
    "        correct_notes += an[\"start-pos-pitch-duration\"] + an[\"start-pos-pitch-duration-dtriole\"] + an[\"start-pos-ptriole-pitch-duration\"] + an[\"start-pos-ptriole-pitch-duration-dtriole\"]\n",
    "        incorrect_notes += write_midi(output[idx], token2word, duration_bins, f\"{PATH_MIDI}/{model_name}/generated_midi_{idx}.midi\")\n",
    " \n",
    "    model_df.at[index,\"correct_notes\"] = (correct_notes/5).__round__(2)\n",
    "    model_df.at[index,\"incorrect_notes\"] = (incorrect_notes/5).__round__(2)\n",
    "    model_df.at[index,\"correct_rate\"] = (correct_notes/(correct_notes+incorrect_notes)).__round__(2)\n",
    "\n",
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b740e33-4072-4e3c-b3f0-7f471aaf645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.to_excel(f\"{PATH_MODELS}/model_stats.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416e543-751c-4d86-98cc-4697915c5669",
   "metadata": {},
   "source": [
    "run \"tar chvfz predictions_midi.tar.gz *\" in terminal midi folder to create and download zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cc98a-ac66-439f-9995-53bedde78d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2469cc5-a929-4fab-97e3-10a9acee4c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f93517dc-e5aa-409e-b220-31b16da1655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Andere Variante ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2e116b1-25ee-40f1-8930-1aac99878b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 120])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(inputs)\n",
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86de9d10-35b3-4286-9e42-264c9696e409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.1162, -2.1350, -3.5313, -1.9780, -3.5414, -1.5776, -1.8704,\n",
       "          -3.5441, -1.1535, -2.6672, -0.8764, -2.2812, -1.6335, -0.8708,\n",
       "          -2.7905, -1.4720, -2.4843, -0.5825, -2.0775, -2.7744, -1.5724,\n",
       "          -3.7235, -1.8095, -2.4802, -2.3428, -2.3748, -3.2765, -2.9800,\n",
       "          -3.1671, -2.6769, -3.6342, -3.3965, -2.9433, -3.3021, -3.6102,\n",
       "          -3.8760, -3.8078, -2.8941, -0.2965, -3.4592, -0.6409, -3.7882,\n",
       "          -1.4499, -3.6240, -0.8940, -3.3144, -1.9948, -3.0505, -2.1582,\n",
       "          -3.2950, -2.2917, -3.4952, -1.5516, -3.7166, -2.3756, -3.3413,\n",
       "          -2.5331, -3.7758, -2.4212, -3.4614, -2.8825, -3.7335, -2.9825,\n",
       "          -2.8619, -2.9172, -3.3198, -3.0439, -2.9400, -1.7772, -3.4107,\n",
       "          -3.0528, -3.1332, -3.2200, -3.2291, -2.9769, -3.1939, -1.9817,\n",
       "          -2.9937, -2.8389, -3.1996, -2.9903, -2.9885, -3.7754, -3.6936,\n",
       "          -3.1062, -3.3149, -3.9010, -3.4983, -3.7158, -3.4427, -3.5639,\n",
       "          -3.5325, -1.8639, -3.7709, -3.4870, -3.2223, -3.6571, -3.4250,\n",
       "          -3.6030, -3.3400, -2.2445,  0.1584,  3.4136,  4.2250,  4.2018,\n",
       "           3.7291,  3.9138,  4.1381,  4.0495,  3.2906,  3.4570,  3.8709,\n",
       "           3.7553,  3.1699,  3.3294,  3.8238,  3.7216,  3.2188, -0.7025,\n",
       "          -0.8708]]], device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76458b6d-c49b-4599-9721-25aece094438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[24]], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temperature value\n",
    "temperature = 13\n",
    "\n",
    "# Convert logits to probabilities using softmax with temperature\n",
    "probs = F.softmax(outputs.logits / temperature, dim=-1)\n",
    "\n",
    "# Sample a token from the probability distribution for each position in the sequence\n",
    "predicted_tokens = torch.multinomial(probs.view(-1, probs.shape[-1]), num_samples=1).view(*probs.shape[:-1])\n",
    "predicted_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5fa664ea-d774-4f8b-9367-f3f5ea2efc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Note-On_83'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(predicted_tokens[0], skip_special_tokens=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [pipenv: PyEnv]",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
