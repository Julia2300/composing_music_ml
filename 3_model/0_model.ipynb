{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim_model, dropout_p, max_len):\n",
    "        super().__init__()\n",
    "        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "        # max_len determines how far the position can have an effect on a token (window)\n",
    "        \n",
    "        # Info\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        \n",
    "        # Encoding - From formula\n",
    "        pos_encoding = torch.zeros(max_len, dim_model)\n",
    "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
    "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n",
    "        \n",
    "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
    "        \n",
    "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
    "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
    "        \n",
    "        # Saving buffer (same as parameter without gradients needed)\n",
    "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
    "        \n",
    "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
    "        # Residual connection + pos encoding\n",
    "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Model from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    # Constructor\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_tokens,\n",
    "        dim_model,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        dropout_p,\n",
    "        max_len=5000,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # INFO\n",
    "        self.model_type = \"Transformer\"\n",
    "        self.dim_model = dim_model\n",
    "\n",
    "        # LAYERS\n",
    "        self.positional_encoder = PositionalEncoding(\n",
    "            dim_model=dim_model, dropout_p=dropout_p, max_len=max_len\n",
    "        )\n",
    "        self.embedding = nn.Embedding(num_tokens, dim_model)\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=dim_model,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_encoder_layers,\n",
    "            num_decoder_layers=num_decoder_layers,\n",
    "            dropout=dropout_p,\n",
    "        )\n",
    "        self.out = nn.Linear(dim_model, num_tokens)\n",
    "        \n",
    "    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None):\n",
    "        # Src size must be (batch_size, src sequence length)\n",
    "        # Tgt size must be (batch_size, tgt sequence length)\n",
    "\n",
    "        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n",
    "        src = self.embedding(src) * math.sqrt(self.dim_model)\n",
    "        tgt = self.embedding(tgt) * math.sqrt(self.dim_model)\n",
    "        src = self.positional_encoder(src)\n",
    "        tgt = self.positional_encoder(tgt)\n",
    "        \n",
    "        # We could use the parameter batch_first=True, but our KDL version doesn't support it yet, so we permute\n",
    "        # to obtain size (sequence length, batch_size, dim_model),\n",
    "        src = src.permute(1,0,2)\n",
    "        tgt = tgt.permute(1,0,2)\n",
    "\n",
    "        # Transformer blocks - Out size = (sequence length, batch_size, num_tokens)\n",
    "        transformer_out = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n",
    "        out = self.out(transformer_out)\n",
    "        \n",
    "        return out\n",
    "      \n",
    "    def get_tgt_mask(self, size) -> torch.tensor:\n",
    "        # Generates a squeare matrix where the each row allows one word more to be seen\n",
    "        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n",
    "        mask = mask.float()\n",
    "        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n",
    "        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n",
    "        \n",
    "        # EX for size=5:\n",
    "        # [[0., -inf, -inf, -inf, -inf],\n",
    "        #  [0.,   0., -inf, -inf, -inf],\n",
    "        #  [0.,   0.,   0., -inf, -inf],\n",
    "        #  [0.,   0.,   0.,   0., -inf],\n",
    "        #  [0.,   0.,   0.,   0.,   0.]]\n",
    "        \n",
    "        return mask\n",
    "    \n",
    "    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n",
    "        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n",
    "        # [False, False, False, True, True, True]\n",
    "        return (matrix == pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, opt, loss_fn, dataloader):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch in tqdm(dataloader):\n",
    "        X, y = batch[:, 0], batch[:, 1]\n",
    "        X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n",
    "\n",
    "        # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "        y_input = y[:,:-1]\n",
    "        y_expected = y[:,1:]\n",
    "        \n",
    "        # Get mask to mask out the next words\n",
    "        sequence_length = y_input.size(1)\n",
    "        tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
    "\n",
    "        # Standard training except we pass in y_input and tgt_mask\n",
    "        pred = model(X, y_input, tgt_mask)\n",
    "\n",
    "        # Permute pred to have batch size first again\n",
    "        pred = pred.permute(1, 2, 0)      \n",
    "        loss = loss_fn(pred, y_expected)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "        total_loss += loss.detach().item()\n",
    "        \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(model, loss_fn, dataloader):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        # negative likelihood and total words to compute perplexity\n",
    "        total_nll = 0\n",
    "        total_words = 0\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            X, y = batch[:, 0], batch[:, 1]\n",
    "            X, y = torch.tensor(X, dtype=torch.long, device=device), torch.tensor(y, dtype=torch.long, device=device)\n",
    "\n",
    "            # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n",
    "            y_input = y[:,:-1]\n",
    "            y_expected = y[:,1:]\n",
    "            \n",
    "            # Get mask to mask out the next words\n",
    "            sequence_length = y_input.size(1)\n",
    "            tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n",
    "\n",
    "            # Standard training except we pass in y_input and src_mask\n",
    "            pred = model(X, y_input, tgt_mask)\n",
    "\n",
    "            # Permute pred to have batch size first again\n",
    "            pred = pred.permute(1, 2, 0)      \n",
    "            loss = loss_fn(pred, y_expected)\n",
    "            total_loss += loss.detach().item()\n",
    "            \n",
    "            # Compute the negative log-likelihood of the test data\n",
    "            pred_norm = torch.softmax(pred, dim=-1)\n",
    "            nll = -torch.log(pred_norm.permute(0, 2, 1).gather(2, y_expected.unsqueeze(2)).squeeze(2)).sum()\n",
    "            total_nll += nll\n",
    "            total_words += len(y_expected)\n",
    "\n",
    "        perplexity = torch.exp(total_nll / total_words)\n",
    "        \n",
    "    return total_loss / len(dataloader), perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input_sequence, max_length=1024, SOS_token=121, EOS_token=122):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    y_input = torch.tensor([[SOS_token]], dtype=torch.long, device=device)\n",
    "\n",
    "    num_tokens = len(input_sequence[0])\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        # Get source mask\n",
    "        tgt_mask = model.get_tgt_mask(y_input.size(1)).to(device)\n",
    "        \n",
    "        pred = model(input_sequence, y_input, tgt_mask)\n",
    "        \n",
    "        next_item = pred.topk(1)[1].view(-1)[-1].item() # num with highest probability\n",
    "        next_item = torch.tensor([[next_item]], device=device)\n",
    "\n",
    "        # Concatenate previous input with predicted best word\n",
    "        y_input = torch.cat((y_input, next_item), dim=1)\n",
    "\n",
    "        # Stop if model predicts end of sentence\n",
    "        if next_item.view(-1).item() == EOS_token:\n",
    "            break\n",
    "\n",
    "    return y_input.view(-1).tolist()\n",
    "\n",
    "def predict_temp(model, input_sequence, max_length=1024, SOS_token=121, EOS_token=122, temperature=0.8):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    y_input = torch.tensor([[SOS_token]], dtype=torch.long, device=device)\n",
    "\n",
    "    num_tokens = len(input_sequence[0])\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        # Get source mask\n",
    "        tgt_mask = model.get_tgt_mask(y_input.size(1)).to(device)\n",
    "        \n",
    "        pred = model(input_sequence, y_input, tgt_mask)\n",
    "        \n",
    "        # Define temperature\n",
    "        temp = temperature\n",
    "\n",
    "        # Apply softmax with temperature scaling\n",
    "        log_probs = F.log_softmax(pred / temp, dim=-1)[0]\n",
    "\n",
    "        # Sample tokens from the probability distribution\n",
    "        token_ids = torch.multinomial(torch.exp(log_probs), num_samples=1)\n",
    "        next_item = token_ids.item()\n",
    "        \n",
    "        #### old version ####\n",
    "        # next_item = pred.topk(1)[1].view(-1)[-1].item() # num with highest probability\n",
    "        #####################\n",
    "        next_item = torch.tensor([[next_item]], device=device)\n",
    "\n",
    "        # Concatenate previous input with predicted best word\n",
    "        y_input = torch.cat((y_input, next_item), dim=1)\n",
    "\n",
    "        # Stop if model predicts end of sentence\n",
    "        if next_item.view(-1).item() == EOS_token:\n",
    "            break\n",
    "\n",
    "    return y_input.view(-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, opt, loss_fn, train_dataloader, val_dataloader, epochs, temperature=0.8, test_sequence=[0], out=\"all\"):\n",
    "    \"\"\"\n",
    "    Method from \"A detailed guide to Pytorch's nn.Transformer() module.\", by\n",
    "    Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n",
    "    \"\"\"\n",
    "    \n",
    "    # Used for plotting later on\n",
    "    train_loss_list, validation_loss_list, perplexity_list = [], [], []\n",
    "    \n",
    "    print(\"Training and validating model\")\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n",
    "        \n",
    "        train_loss = train_loop(model, opt, loss_fn, train_dataloader)\n",
    "        train_loss_list += [train_loss]\n",
    "        \n",
    "        validation_loss, perplexity = validation_loop(model, loss_fn, val_dataloader)\n",
    "        validation_loss_list += [validation_loss]\n",
    "        perplexity_list += [perplexity]\n",
    "        \n",
    "        if (out == \"all\" or (epoch+1) % 10 == 0 or epoch == epochs-1) and out != \"none\":\n",
    "            \n",
    "            test_seq = torch.tensor([test_sequence], dtype=torch.long, device=device)\n",
    "            pred = predict(model, test_seq, max_length=64)\n",
    "            pred_temp = predict_temp(model, test_seq, max_length=64, temperature=temperature)\n",
    "        \n",
    "            print(f\"Training loss: {train_loss:.4f}\")\n",
    "            print(f\"Validation loss: {validation_loss:.4f}\")\n",
    "            print(f\"Perplexity: {perplexity:.4f}\")\n",
    "            print(\"Predicted sequence: \", pred)\n",
    "            print(\"Predicted sequence (temperature): \", pred_temp)\n",
    "\n",
    "        print()\n",
    "        \n",
    "    return train_loss_list, validation_loss_list, perplexity_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTE_TYPES_following = {\n",
    "    \"start\": [\"pos\"],\n",
    "    \"start-pos\": [\"pitch\", \"ptriole\"],\n",
    "    \"start-pos-ptriole\": [\"pitch\"],\n",
    "    \"start-pos-pitch\": [\"duration\"],\n",
    "    \"start-pos-ptriole-pitch\": [\"duration\"],\n",
    "    \"start-pos-pitch-duration\": [\"dtriole\"],\n",
    "    \"start-pos-pitch-duration-dtriole\": [],\n",
    "    \"start-pos-ptriole-pitch-duration\": [\"dtriole\"],\n",
    "    \"start-pos-ptriole-pitch-duration-dtriole\": [],\n",
    "}\n",
    "\n",
    "def analyze_token_sequence(seq):\n",
    "    counts = {note_type: 0 for note_type in NOTE_TYPES_following}\n",
    "    current_note_type = \"start\"\n",
    "\n",
    "    for token in seq:\n",
    "\n",
    "        if token_type(token) in NOTE_TYPES_following[current_note_type]:\n",
    "            current_note_type += \"-\" + token_type(token)\n",
    "        else:\n",
    "            counts[current_note_type] += 1\n",
    "            if token_type(token) == \"pos\":\n",
    "                current_note_type = \"start-pos\"\n",
    "            else:\n",
    "                current_note_type = \"start\"\n",
    "    \n",
    "    counts[current_note_type] += 1\n",
    "    return counts\n",
    "\n",
    "def token_type(token):\n",
    "    if token in range(102, 118):\n",
    "        return \"pos\"\n",
    "    elif token in range(1, 37):\n",
    "        return \"pitch\"\n",
    "    elif token in range(118, 120):\n",
    "        return \"ptriole\"\n",
    "    elif token in range(37, 101):\n",
    "        return \"duration\"\n",
    "    elif token == 101:\n",
    "        return \"dtriole\"\n",
    "    elif token == 0:\n",
    "        return \"Bar\"\n",
    "    elif token in range(120, 123):\n",
    "        return \"Bar\"\n",
    "    else:\n",
    "        raise ValueError(\"Invalid token: {}\".format(token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Song Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 119 tokens\n",
    "# <PAD> 120\n",
    "# <SOS> 121\n",
    "# <EOS> 122\n",
    "PAD = 120\n",
    "SOS = 121\n",
    "EOS = 122"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "803"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data.json', 'r') as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "token_list = []\n",
    "for song in data:\n",
    "    token_list.append(data[song])\n",
    "\n",
    "len(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = [len(song) for song in token_list]\n",
    "plt.hist(lengths, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify_data_max_token_length(data, batch_size, max_token_lengths, padding=True, padding_token=PAD, start_token=SOS, end_token=EOS):\n",
    "    batches = []\n",
    "    for idx in range(0, len(data), batch_size): # HIER GEHEN DIE LETZTEN 3 SONGS VERLOREN\n",
    "        # We make sure we dont get the last bit if its not batch_size size\n",
    "        if idx + batch_size < len(data):\n",
    "            if padding:\n",
    "                for seq_idx in range(batch_size):\n",
    "                    # when song length smaller add <PAD> else cut tokens\n",
    "                    if len(data[idx + seq_idx]) < max_token_lengths-2:\n",
    "                        remaining_length = max_token_lengths - 2 - len(data[idx + seq_idx])\n",
    "                        data[idx + seq_idx] = [start_token] + data[idx + seq_idx] + [end_token] + [padding_token] * remaining_length\n",
    "                    else:\n",
    "                        data[idx + seq_idx] = [start_token] + data[idx + seq_idx][:max_token_lengths-2] + [end_token]\n",
    "            # double token seq as in and output\n",
    "            data[idx : idx + batch_size] = [[token_seq, token_seq] for token_seq in data[idx : idx + batch_size]]\n",
    "            batches.append(np.array(data[idx : idx + batch_size]).astype(np.int64))\n",
    "\n",
    "    print(f\"{len(batches)} batches of size {batch_size}\")\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_data(data, window_size):\n",
    "    sliced_data = []\n",
    "    for d in data:\n",
    "        for i in range(0, len(d) - window_size + 1, window_size):\n",
    "            window = d[i:i+window_size]\n",
    "            sliced_data.append(window)\n",
    "    return sliced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIM_MODEL = 128\n",
    "NHEAD = 4\n",
    "NUM_ENCODER_LAYERS = 6\n",
    "NUM_DECODER_LAYERS = 6\n",
    "DROPOUT = 0\n",
    "LEARNING_RATE = 0.001\n",
    "MAX_TOKEN_LENGTH = 128\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"DIM_MODEL\": DIM_MODEL,\n",
    "    \"NHEAD\": NHEAD,\n",
    "    \"NUM_ENCODER_LAYERS\": NUM_ENCODER_LAYERS,\n",
    "    \"NUM_DECODER_LAYERS\": NUM_DECODER_LAYERS,\n",
    "    \"DROPOUT\": DROPOUT,\n",
    "    \"LEARNING_RATE\": LEARNING_RATE,\n",
    "    \"MAX_TOKEN_LENGTH\": MAX_TOKEN_LENGTH,\n",
    "    \"EPOCHS\": EPOCHS,\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DIM_MODEL</th>\n",
       "      <td>512.000</td>\n",
       "      <td>512.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NHEAD</th>\n",
       "      <td>8.000</td>\n",
       "      <td>8.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM_ENCODER_LAYERS</th>\n",
       "      <td>12.000</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM_DECODER_LAYERS</th>\n",
       "      <td>12.000</td>\n",
       "      <td>12.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DROPOUT</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEARNING_RATE</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAX_TOKEN_LENGTH</th>\n",
       "      <td>256.000</td>\n",
       "      <td>256.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EPOCHS</th>\n",
       "      <td>200.000</td>\n",
       "      <td>200.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BATCH_SIZE</th>\n",
       "      <td>4.000</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model1   model2\n",
       "DIM_MODEL           512.000  512.000\n",
       "NHEAD                 8.000    8.000\n",
       "NUM_ENCODER_LAYERS   12.000   12.000\n",
       "NUM_DECODER_LAYERS   12.000   12.000\n",
       "DROPOUT               0.000    0.000\n",
       "LEARNING_RATE         0.001    0.001\n",
       "MAX_TOKEN_LENGTH    256.000  256.000\n",
       "EPOCHS              200.000  200.000\n",
       "BATCH_SIZE            4.000    4.000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {\"model1\": hyperparameters, \"model2\": hyperparameters}\n",
    "df = pd.DataFrame(dic)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count:  3492\n",
      "data 90%:    3142\n",
      "785 batches of size 4\n",
      "87 batches of size 4\n"
     ]
    }
   ],
   "source": [
    "sliced_songs = slice_data(token_list, MAX_TOKEN_LENGTH)\n",
    "percent_90 = int(len(sliced_songs) * 0.9)\n",
    "\n",
    "print(\"data count: \", len(sliced_songs))\n",
    "print(\"data 90%:   \", percent_90)\n",
    "\n",
    "batches_train = batchify_data_max_token_length(\n",
    "    sliced_songs[:percent_90],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_token_lengths=MAX_TOKEN_LENGTH\n",
    "    )\n",
    "batches_test = batchify_data_max_token_length(\n",
    "    sliced_songs[percent_90:],\n",
    "    batch_size=BATCH_SIZE,\n",
    "    max_token_lengths=MAX_TOKEN_LENGTH\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    num_tokens=123,\n",
    "    dim_model=DIM_MODEL,\n",
    "    num_heads=NHEAD,\n",
    "    num_encoder_layers=NUM_ENCODER_LAYERS,\n",
    "    num_decoder_layers=NUM_DECODER_LAYERS,\n",
    "    dropout_p=DROPOUT\n",
    ").to(device)\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if loading from checkpoint\n",
    "\n",
    "checkpoint = torch.load(\"model_checkpoints/model_8.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "opt.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "train_loss_list = checkpoint['train_loss']\n",
    "validation_loss_list = checkpoint['val_loss']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and validating model\n",
      "------------------------- Epoch 1 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:19<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 2 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 3 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 4 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 5 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 6 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 7 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:18<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 8 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 9 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 10 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.7548\n",
      "Validation loss: 1.7757\n",
      "Perplexity: inf\n",
      "Predicted sequence:  [121, 0, 107, 8, 8, 8, 0, 107, 101, 0, 107, 8, 40, 0, 107, 8, 40, 0, 108, 8, 40, 108, 8, 40, 108, 8, 40, 0, 107, 8, 40, 0, 107, 8, 40, 108, 8, 40, 0, 107, 13, 40, 108, 8, 40, 108, 8, 40, 108, 8, 40, 108, 8, 40, 108, 8, 40, 108, 8, 40, 108, 8, 40, 108, 13]\n",
      "Predicted sequence (temperature):  [121, 6, 101, 91, 101, 0, 0, 107, 113, 108, 8, 101, 8, 17, 101, 101, 52, 20, 108, 40, 0, 20, 101, 72, 0, 0, 8, 8, 13, 13, 0, 0, 92, 111, 112, 10, 15, 20, 15, 13, 40, 101, 1, 10, 13, 119, 101, 0, 13, 9, 0, 8, 0, 107, 60, 13, 13, 13, 0, 0, 5, 101, 101, 101, 0]\n",
      "\n",
      "------------------------- Epoch 11 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 12 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 13 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 14 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 15 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 16 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 17 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 18 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 19 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 20 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.6696\n",
      "Validation loss: 1.7080\n",
      "Perplexity: inf\n",
      "Predicted sequence:  [121, 0, 107, 101, 0, 107, 13, 44, 101, 0, 107, 13, 44, 101, 0, 107, 13, 44, 101, 0, 107, 13, 44, 101, 0, 107, 13, 44, 101, 0, 107, 13, 44, 101, 0, 107, 13, 44, 101, 0, 107, 13, 44, 101, 0, 107, 13, 44, 101, 0, 107, 13, 44, 101, 0, 107, 13, 44, 101, 0, 107, 13, 44, 101, 0]\n",
      "Predicted sequence (temperature):  [121, 101, 111, 6, 0, 110, 68, 112, 0, 20, 0, 0, 84, 0, 46, 101, 20, 0, 0, 0, 8, 76, 28, 22, 29, 0, 0, 0, 0, 0, 44, 0, 0, 0, 56, 0, 114, 13, 112, 119, 101, 108, 101, 101, 108, 0, 0, 111, 3, 45, 107, 101, 0, 0, 6, 101, 103, 13, 101, 101, 0, 13, 0, 3, 109]\n",
      "\n",
      "------------------------- Epoch 21 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 22 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 23 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 24 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 25 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 26 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 27 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 28 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 29 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 30 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.6059\n",
      "Validation loss: 1.6554\n",
      "Perplexity: inf\n",
      "Predicted sequence:  [121, 0, 107, 101, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0, 107, 6, 0]\n",
      "Predicted sequence (temperature):  [121, 0, 0, 0, 101, 0, 107, 117, 12, 13, 8, 0, 13, 101, 108, 101, 3, 108, 0, 101, 5, 15, 0, 28, 119, 0, 0, 116, 111, 111, 84, 108, 0, 0, 13, 107, 108, 112, 0, 82, 0, 74, 108, 101, 56, 0, 101, 108, 0, 0, 0, 116, 101, 0, 0, 118, 0, 0, 0, 24, 0, 101, 0, 0, 101]\n",
      "\n",
      "------------------------- Epoch 31 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 32 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 33 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 34 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 35 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 36 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 37 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 38 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 39 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 40 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.4725\n",
      "Validation loss: 1.5271\n",
      "Perplexity: inf\n",
      "Predicted sequence:  [121, 0, 0, 0, 107, 0, 107, 0, 108, 0, 0, 107, 6, 0, 107, 6, 0, 0, 107, 6, 0, 0, 107, 6, 0, 0, 107, 6, 0, 107, 6, 0, 0, 107, 6, 0, 0, 107, 6, 0, 0, 107, 6, 0, 107, 6, 0, 0, 107, 6, 0, 0, 107, 6, 0, 0, 107, 6, 0, 107, 6, 0, 0, 107, 6]\n",
      "Predicted sequence (temperature):  [121, 0, 0, 108, 50, 0, 108, 107, 11, 91, 15, 116, 1, 0, 0, 0, 0, 0, 0, 0, 53, 0, 0, 0, 0, 0, 0, 116, 3, 0, 26, 0, 119, 118, 0, 0, 6, 101, 0, 0, 0, 20, 0, 0, 0, 16, 84, 10, 0, 0, 0, 0, 0, 0, 53, 0, 0, 0, 101, 0, 0, 101, 6, 111, 0]\n",
      "\n",
      "------------------------- Epoch 41 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 42 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 43 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:18<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 44 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 45 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 46 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 47 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 48 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 49 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 50 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:18<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.2823\n",
      "Validation loss: 1.3313\n",
      "Perplexity: inf\n",
      "Predicted sequence:  [121, 0, 0, 0, 0, 0, 107, 101, 0, 0, 0, 107, 6, 0, 0, 0, 107, 6, 0, 0, 0, 107, 6, 0, 0, 0, 107, 6, 0, 0, 0, 107, 6, 0, 0, 0, 107, 6, 0, 0, 0, 107, 6, 0, 0, 0, 107, 6, 0, 0, 0, 107, 6, 0, 0, 0, 107, 6, 0, 0, 0, 107, 6, 0, 0]\n",
      "Predicted sequence (temperature):  [121, 0, 101, 0, 0, 116, 0, 25, 48, 0, 0, 101, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 121, 0, 0, 0, 0, 0, 0, 70, 101, 0, 0, 0, 0, 116, 0, 0, 0, 0, 0, 0, 46, 101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 13, 0, 0, 0, 0]\n",
      "\n",
      "------------------------- Epoch 51 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:18<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 52 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 53 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 54 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 55 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:12<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 56 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 57 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 58 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 59 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 60 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.1842\n",
      "Validation loss: 1.2565\n",
      "Perplexity: inf\n",
      "Predicted sequence:  [121, 0, 0, 101, 0, 0, 107, 101, 0, 0, 107, 6, 0, 0, 107, 6, 48, 0, 0, 108, 6, 0, 0, 107, 6, 48, 0, 0, 107, 6, 48, 0, 0, 107, 6, 48, 0, 0, 107, 6, 48, 0, 0, 107, 6, 48, 0, 0, 107, 6, 48, 0, 0, 107, 6, 48, 0, 0, 107, 6, 48, 0, 0, 107, 6]\n",
      "Predicted sequence (temperature):  [121, 0, 101, 0, 0, 0, 0, 0, 0, 107, 0, 0, 0, 78, 0, 0, 0, 0, 0, 0, 0, 0, 0, 19, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 101, 0, 12, 0, 101, 0, 0, 60, 0, 0, 0, 0, 101, 0, 6, 0, 25, 101, 0, 101, 99, 101, 0, 101, 107, 0, 0, 13, 0]\n",
      "\n",
      "------------------------- Epoch 61 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 62 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 63 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 64 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 65 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 66 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 67 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 68 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 69 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 70 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.1268\n",
      "Validation loss: 1.2155\n",
      "Perplexity: inf\n",
      "Predicted sequence:  [121, 0, 0, 0, 108, 0, 101, 0, 101, 0, 0, 107, 6, 48, 0, 0, 0, 107, 6, 48, 0, 0, 0, 107, 6, 48, 0, 0, 0, 107, 6, 48, 0, 0, 0, 107, 6, 60, 0, 0, 0, 107, 6, 60, 0, 0, 0, 107, 6, 60, 0, 0, 0, 107, 6, 60, 0, 0, 116, 119, 8, 60, 0, 0, 0]\n",
      "Predicted sequence (temperature):  [121, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 56, 101, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 61, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 13, 0, 101, 0, 0, 0, 26]\n",
      "\n",
      "------------------------- Epoch 71 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 72 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 73 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 74 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 75 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 76 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 77 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 78 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 79 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 80 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0725\n",
      "Validation loss: 1.1792\n",
      "Perplexity: inf\n",
      "Predicted sequence:  [121, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 101, 0]\n",
      "Predicted sequence (temperature):  [121, 0, 0, 0, 20, 0, 101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "------------------------- Epoch 81 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 82 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 83 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 84 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 85 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 86 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 87 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 88 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 89 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 90 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.0322\n",
      "Validation loss: 1.1574\n",
      "Perplexity: inf\n",
      "Predicted sequence:  [121, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 101, 0]\n",
      "Predicted sequence (temperature):  [121, 0, 0, 0, 47, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 101, 0, 101, 0, 0, 0, 0, 0, 0, 0, 101, 101, 101, 101, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 101, 0, 101, 0]\n",
      "\n",
      "------------------------- Epoch 91 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 92 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 93 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 94 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 95 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 96 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 97 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 98 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 99 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 100 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.9995\n",
      "Validation loss: 1.1422\n",
      "Perplexity: inf\n",
      "Predicted sequence:  [121, 0, 0, 0, 108, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Predicted sequence (temperature):  [121, 0, 0, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 101]\n",
      "\n",
      "------------------------- Epoch 101 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 102 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 103 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 104 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 105 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 106 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 107 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 108 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 109 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 110 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.9721\n",
      "Validation loss: 1.1350\n",
      "Perplexity: inf\n",
      "Predicted sequence:  [121, 0, 0, 108, 0, 0, 108, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Predicted sequence (temperature):  [121, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 13, 101, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0]\n",
      "\n",
      "------------------------- Epoch 111 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 112 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 113 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 114 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 115 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 116 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 117 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 118 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 119 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 120 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.9477\n",
      "Validation loss: 1.1285\n",
      "Perplexity: inf\n",
      "Predicted sequence:  [121, 0, 0, 108, 0, 0, 108, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0]\n",
      "Predicted sequence (temperature):  [121, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "------------------------- Epoch 121 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 122 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 123 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 124 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 125 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 126 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 127 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 128 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 129 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 130 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.9222\n",
      "Validation loss: 1.1276\n",
      "Perplexity: inf\n",
      "Predicted sequence:  [121, 0, 0, 108, 0, 0, 108, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 0]\n",
      "Predicted sequence (temperature):  [121, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 21, 0, 0, 26, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 122]\n",
      "\n",
      "------------------------- Epoch 131 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 132 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 133 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 134 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 135 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 136 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 137 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 138 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 139 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 785/785 [02:17<00:00,  5.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------- Epoch 140 -------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 255/785 [00:44<01:29,  5.95it/s]"
     ]
    }
   ],
   "source": [
    "train_loss_list, validation_loss_list, perplexity_list = fit(model, opt, loss_fn, batches_train, batches_test, EPOCHS, out=\"not_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_list, color=\"blue\")\n",
    "plt.plot(validation_loss_list, color=\"orange\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0\n",
      "Input: [0, 104, 17, 38, 105]\n",
      "Continuation: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 38, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Example 1\n",
      "Input: [0, 103]\n",
      "Continuation: [103, 103, 0, 103, 0, 0, 0, 0, 103, 0, 103, 0, 103, 103, 0, 103, 103, 101, 118, 0, 0, 103, 103, 0, 0, 103, 103, 103, 103, 103, 0, 103, 0, 103, 103, 103, 103, 103, 0, 0, 0, 0, 103, 103, 103, 103, 103, 103, 0, 0, 0, 103, 103, 103, 0, 103, 0, 103, 0, 0, 103, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here we test some examples to observe how the model predicts\n",
    "examples = [\n",
    "    torch.tensor([[SOS, 0, 104, 17, 38, 105, EOS]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[SOS, 0, 103, EOS]], dtype=torch.long, device=device)\n",
    "]\n",
    "results = []\n",
    "\n",
    "for idx, example in enumerate(examples):\n",
    "    result = predict_temp(model, example, max_length=64, temperature=0.8)\n",
    "    results.append(result)\n",
    "    print(f\"Example {idx}\")\n",
    "    print(f\"Input: {example.view(-1).tolist()[1:-1]}\")\n",
    "    print(f\"Continuation: {result[1:-1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0\n",
      "Input: [0, 104, 17, 38, 105]\n",
      "Continuation: [0, 111, 0, 0, 118, 76, 0, 0, 0, 54, 0, 24, 0, 0, 0, 0, 101, 0, 111, 0, 81, 105, 0, 0, 20, 118, 0, 0, 0, 0, 0, 0, 0, 0, 0, 101, 0, 0, 0, 0, 15, 0, 0, 109, 38, 0, 0, 0, 103, 0, 118, 0, 0, 12, 7, 0, 0, 0, 101, 0, 0, 0, 118]\n",
      "\n",
      "Example 1\n",
      "Input: [0, 103]\n",
      "Continuation: [0, 112, 0, 103, 103, 102, 0, 17, 102, 103, 112, 15, 111, 8, 103, 103, 103, 0, 0, 0, 103, 0, 0, 103, 103, 103, 32, 35, 61, 103, 0, 0, 117, 103, 103, 103, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here we test some examples to observe how the model predicts\n",
    "examples = [\n",
    "    torch.tensor([[SOS, 0, 104, 17, 38, 105, EOS]], dtype=torch.long, device=device),\n",
    "    torch.tensor([[SOS, 0, 103, EOS]], dtype=torch.long, device=device)\n",
    "]\n",
    "results = []\n",
    "\n",
    "for idx, example in enumerate(examples):\n",
    "    result = predict_temp(model, example, max_length=64, temperature=1.2)\n",
    "    results.append(result)\n",
    "    print(f\"Example {idx}\")\n",
    "    print(f\"Input: {example.view(-1).tolist()[1:-1]}\")\n",
    "    print(f\"Continuation: {result[1:-1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>start</th>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos</th>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-ptriole</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-pitch</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-ptriole-pitch</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-pitch-duration</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-pitch-duration-dtriole</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-ptriole-pitch-duration</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start-pos-ptriole-pitch-duration-dtriole</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0   1\n",
       "start                                     56  10\n",
       "start-pos                                  5  17\n",
       "start-pos-ptriole                          0   0\n",
       "start-pos-pitch                            0   3\n",
       "start-pos-ptriole-pitch                    0   0\n",
       "start-pos-pitch-duration                   0   0\n",
       "start-pos-pitch-duration-dtriole           0   0\n",
       "start-pos-ptriole-pitch-duration           0   0\n",
       "start-pos-ptriole-pitch-duration-dtriole   0   0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {}\n",
    "for idx, res in enumerate(results):\n",
    "    an = analyze_token_sequence(res)\n",
    "    dic[idx] = an\n",
    "\n",
    "pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': 200,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': opt.state_dict(),\n",
    "            'train_loss': train_loss_list,\n",
    "            'val_loss': validation_loss_list,\n",
    "            }, \"model_checkpoints/model_9.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [pipenv: PyEnv]",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
